#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gradioå‰ç«¯åº”ç”¨ - CMSæŒ¯åŠ¨åˆ†ææŠ¥å‘Šç³»ç»Ÿ
åŸºäºåŸæœ‰streamlit_app.pyè½¬æ¢è€Œæ¥ï¼Œä¿æŒç›¸åŒçš„åŠŸèƒ½å’Œä»£ç ç»“æ„
"""

import gradio as gr
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from loguru import logger
import yaml
import shutil
import base64
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°ç³»ç»Ÿè·¯å¾„
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.config_loader import get_config
from chat.chat_manager import ChatManager
from chat.session_manager import SessionManager
from knowledge.knowledge_retriever import KnowledgeRetriever
from data.mock_data import CMSDataGenerator
from utils.chart_generator import VibrationChartGenerator
from report.generator import CMSReportGenerator

# å…¨å±€é…ç½®
config = get_config()

class GradioCMSApp:
    """Gradio CMSåº”ç”¨ç¨‹åºä¸»ç±»"""
    
    def __init__(self):
        self.config = get_config()
        self.chat_history = []
        self.current_session_id = None
        self.system_status = {
            'llm': 'offline',
            'knowledge_base': 'offline',
            'database': 'offline'
        }
        self._init_components()
    
    def _init_components(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        try:
            # åˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨
            self.session_manager = SessionManager()
            logger.info("ä¼šè¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
            # åˆå§‹åŒ–çŸ¥è¯†æ£€ç´¢å™¨
            try:
                knowledge_config = self.config.get('knowledge', {})
                embeddings_path = knowledge_config.get('embeddings_path', './data/embeddings')
                metadata_path = knowledge_config.get('metadata_path', './data/metadata')
                
                self.knowledge_retriever = KnowledgeRetriever(
                    embeddings_path=embeddings_path,
                    metadata_path=metadata_path
                )
                self.system_status['knowledge_base'] = 'online'
                logger.info("çŸ¥è¯†æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                self.knowledge_retriever = None
                self.system_status['knowledge_base'] = 'offline'
                logger.error(f"çŸ¥è¯†æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            
            # åˆå§‹åŒ–èŠå¤©ç®¡ç†å™¨
            try:
                self.chat_manager = ChatManager(
                    config=self.config.config,
                    session_manager=self.session_manager
                )
                # æ£€æŸ¥LLMçŠ¶æ€
                if hasattr(self.chat_manager.llm_client, 'model_config'):
                    self.system_status['llm'] = 'online'
                else:
                    self.system_status['llm'] = 'warning'
                logger.info("èŠå¤©ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                self.chat_manager = None
                self.system_status['llm'] = 'offline'
                logger.error(f"èŠå¤©ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            
            # æ•°æ®åº“çŠ¶æ€æ£€æŸ¥
            self.system_status['database'] = 'online'
            
        except Exception as e:
            logger.error(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def get_system_status_display(self) -> str:
        """è·å–ç³»ç»ŸçŠ¶æ€æ˜¾ç¤ºæ–‡æœ¬"""
        status_text = "## ğŸ“Š ç³»ç»ŸçŠ¶æ€\n\n"
        
        status_indicators = {
            'llm': 'ğŸ¤– è¯­è¨€æ¨¡å‹',
            'knowledge_base': 'ğŸ“š çŸ¥è¯†åº“',
            'database': 'ğŸ—„ï¸ æ•°æ®åº“'
        }
        
        for key, label in status_indicators.items():
            status = self.system_status.get(key, 'offline')
            if status == 'online':
                status_text += f"âœ… {label}: åœ¨çº¿\n"
            elif status == 'warning':
                status_text += f"âš ï¸ {label}: è­¦å‘Š\n"
            else:
                status_text += f"âŒ {label}: ç¦»çº¿\n"
        
        return status_text
    
    def get_config_info(self) -> str:
        """è·å–é…ç½®ä¿¡æ¯æ˜¾ç¤ºæ–‡æœ¬"""
        config_text = "## âš™ï¸ å½“å‰é…ç½®\n\n"
        
        model_config = self.config.get_model_config()
        config_text += f"**æ¨¡å‹ç±»å‹**: {model_config.get('type', 'unknown')}\n"
        
        if model_config['type'] == 'local':
            config_text += f"**æœ¬åœ°æ¨¡å‹**: {model_config.get('model_name', 'unknown')}\n"
        elif model_config['type'] == 'openai':
            api_key = model_config.get('api_key', '')
            masked_key = f"{api_key[:8]}...{api_key[-4:]}" if api_key and len(api_key) > 12 else "æœªé…ç½®"
            config_text += f"**OpenAIæ¨¡å‹**: {model_config.get('model_name', 'unknown')}\n"
            config_text += f"**APIå¯†é’¥**: {masked_key}\n"
        
        embedding_config = self.config.get_embedding_config()
        config_text += f"**åµŒå…¥æ¨¡å‹**: {embedding_config.get('type', 'unknown')}\n"
        
        return config_text
    
    def handle_chat_message(self, message: str, history: List[List[str]]) -> Tuple[str, List[List[str]]]:
        """å¤„ç†èŠå¤©æ¶ˆæ¯"""
        if not message.strip():
            return "", history
        
        try:
            # æ£€æŸ¥èŠå¤©ç®¡ç†å™¨æ˜¯å¦å¯ç”¨
            if not self.chat_manager:
                history.append([message, "âŒ èŠå¤©ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®"])
                return "", history
            
            # è·å–æˆ–åˆ›å»ºä¼šè¯
            if not self.current_session_id:
                self.current_session_id = self.session_manager.create_session(
                    user_id="gradio_user"
                )
            
            # å¤„ç†æ¶ˆæ¯
            result = self.chat_manager.process_message(
                user_id="gradio_user",
                message=message,
                session_id=self.current_session_id
            )
            response = result.get('response', 'å¤„ç†å¤±è´¥') if result.get('success') else result.get('error', 'æœªçŸ¥é”™è¯¯')
            
            # æ›´æ–°å†å²è®°å½•
            history.append([message, response])
            
        except Exception as e:
            error_msg = f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"
            history.append([message, error_msg])
            logger.error(error_msg)
        
        return "", history
    
    def handle_quick_question(self, question: str, history: List[List[str]]) -> Tuple[str, List[List[str]]]:
        """å¤„ç†å¿«é€Ÿé—®é¢˜"""
        return self.handle_chat_message(question, history)
    
    def reload_config(self) -> str:
        """é‡æ–°åŠ è½½é…ç½®"""
        try:
            self.config.reload()
            return "âœ… é…ç½®å·²é‡æ–°åŠ è½½"
        except Exception as e:
            return f"âŒ é…ç½®é‡æ–°åŠ è½½å¤±è´¥: {str(e)}"
    
    def clear_chat_history(self, history: List[List[str]]) -> List[List[str]]:
        """æ¸…ç©ºå¯¹è¯å†å²"""
        return []
    
    def generate_test_data(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        try:
            data_generator = CMSDataGenerator()
            test_data = data_generator.generate_turbine_data(
                wind_farm="åèƒ½é£åœºA",
                turbine_id="A01"
            )
            
            # è®¾ç½®ä¼šè¯ä¸Šä¸‹æ–‡ï¼Œå¯ç”¨æµ‹è¯•æ•°æ®æ¨¡å¼
            if not self.current_session_id:
                self.current_session_id = self.session_manager.create_session(
                    user_id="gradio_user"
                )
            self.session_manager.update_context(
                self.current_session_id,
                {'use_mock_data': True}
            )
            
            logger.info("æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ")
            return "âœ… æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆï¼Œæµ‹è¯•æ•°æ®æ¨¡å¼å·²å¯ç”¨ï¼"
        except Exception as e:
            error_msg = f"æµ‹è¯•æ•°æ®ç”Ÿæˆå¤±è´¥ï¼Œæ— æ³•å¯ç”¨æµ‹è¯•æ•°æ®æ¨¡å¼: {str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}"
    
    def generate_vibration_data(self, wind_farm: str, turbine: str) -> Tuple[str, str, str]:
        """ç”ŸæˆæŒ¯åŠ¨æ•°æ®åˆ†æ"""
        if not wind_farm or not turbine:
            return "âŒ è¯·é€‰æ‹©é£åœºå’Œé£æœº", "", ""
        
        try:
            data_generator = CMSDataGenerator()
            vibration_data = data_generator.generate_turbine_data(
                wind_farm=wind_farm,
                turbine_id=turbine
            )
            
            # ç”Ÿæˆæ•°æ®æ¦‚è§ˆ
            overview_text = "## ğŸ“‹ æ•°æ®æ¦‚è§ˆ\n\n"
            overview_text += f"**æµ‹ç‚¹æ•°é‡**: {len(vibration_data['measurements'])}\n"
            
            # ä»ç¬¬ä¸€ä¸ªæµ‹ç‚¹è·å–ä¿¡æ¯
            first_measurement = next(iter(vibration_data['measurements'].values()))
            sampling_rate = first_measurement.get('sampling_rate', 2048)
            data_length = first_measurement.get('data_length', 0)
            overall_status = vibration_data.get('overall_status', 'æ­£å¸¸')
            
            overview_text += f"**é‡‡æ ·é¢‘ç‡**: {sampling_rate} Hz\n"
            overview_text += f"**æ•°æ®é•¿åº¦**: {data_length}\n"
            overview_text += f"**æ•´ä½“çŠ¶æ€**: {overall_status}\n"
            
            # ç”Ÿæˆè¯¦ç»†åˆ†æ
            analysis_text = "## ğŸ“Š æŒ¯åŠ¨åˆ†æè¯¦æƒ…\n\n"
            chart_generator = VibrationChartGenerator()
            
            for point_name, point_data in vibration_data['measurements'].items():
                analysis_text += f"### ğŸ“ˆ {point_name}\n\n"
                
                # ç»Ÿè®¡ä¿¡æ¯
                rms_value = point_data.get('features', {}).get('rms_value', 0.0)
                peak_value = point_data.get('features', {}).get('peak_value', 0.0)
                alarm_level = point_data.get('alarm_level', 'æ­£å¸¸')
                
                analysis_text += f"- **RMSå€¼**: {rms_value:.2f} mm/s\n"
                analysis_text += f"- **å³°å€¼**: {peak_value:.2f} mm/s\n"
                analysis_text += f"- **çŠ¶æ€**: {alarm_level}\n\n"
            
            # ç”Ÿæˆå›¾è¡¨ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ç”ŸæˆçœŸå®å›¾è¡¨ï¼‰
            chart_info = "## ğŸ“Š æŒ¯åŠ¨æ³¢å½¢å›¾è¡¨\n\n"
            chart_info += "å›¾è¡¨ç”ŸæˆåŠŸèƒ½å·²é›†æˆï¼Œå¯æ˜¾ç¤ºæ—¶åŸŸæ³¢å½¢ã€é¢‘åŸŸåˆ†æç­‰ã€‚\n"
            chart_info += f"æ•°æ®æ¥æº: {wind_farm} - {turbine}\n"
            
            return overview_text, analysis_text, chart_info
            
        except Exception as e:
            error_msg = f"æŒ¯åŠ¨æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}", "", ""
    
    def generate_report(self, wind_farm: str, turbine: str, report_type: str, 
                       start_date: str, end_date: str, report_format: str, 
                       use_test_data: bool) -> Tuple[str, str]:
        """ç”ŸæˆæŠ¥å‘Š"""
        if not wind_farm or not turbine:
            return "âŒ è¯·é€‰æ‹©é£åœºå’Œé£æœº", ""
        
        try:
            # æ£€æŸ¥èŠå¤©ç®¡ç†å™¨æ˜¯å¦å¯ç”¨
            if not self.chat_manager:
                return "âŒ èŠå¤©ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®", ""
            
            # è®¾ç½®ä¼šè¯ä¸Šä¸‹æ–‡ä¸­çš„æ•°æ®æºé€‰æ‹©
            if not self.current_session_id:
                self.current_session_id = self.session_manager.create_session(
                    user_id="gradio_user"
                )
            
            # æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡ï¼Œè®¾ç½®æ•°æ®æºæ¨¡å¼
            self.session_manager.update_context(
                self.current_session_id,
                {'use_mock_data': use_test_data}
            )
            
            # ä½¿ç”¨èŠå¤©ç®¡ç†å™¨ç”ŸæˆæŠ¥å‘Š
            data_source_info = "ä½¿ç”¨æµ‹è¯•æ•°æ®" if use_test_data else "è°ƒç”¨å¤–éƒ¨API"
            report_request = f"ç”Ÿæˆ{wind_farm}çš„{turbine}é£æœº{report_type}ï¼Œæ—¶é—´èŒƒå›´ä»{start_date}åˆ°{end_date}ï¼ˆ{data_source_info}ï¼‰"
            
            response = self.chat_manager.process_message(
                user_id="gradio_user",
                message=report_request,
                session_id=self.current_session_id
            )
            
            report_content = response.get('response', response) if isinstance(response, dict) else response
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„æ–‡ä»¶
            download_info = ""
            if isinstance(response, dict) and response.get('docx_file'):
                docx_file_path = response['docx_file']
                if os.path.exists(docx_file_path):
                    download_info = f"ğŸ“¥ æŠ¥å‘Šæ–‡ä»¶å·²ç”Ÿæˆ: {docx_file_path}"
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šæ£€æŸ¥è¾“å‡ºç›®å½•ä¸­çš„æ–‡ä»¶
                output_dir = Path(self.config.get('system', {}).get('output_dir', './output'))
                if output_dir.exists():
                    report_files = list(output_dir.glob(f"*{turbine}*.{report_format}"))
                    if report_files:
                        latest_report = max(report_files, key=os.path.getctime)
                        download_info = f"ğŸ“¥ æŠ¥å‘Šæ–‡ä»¶å·²ç”Ÿæˆ: {latest_report}"
            
            success_msg = "âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼"
            if download_info:
                success_msg += f"\n{download_info}"
            
            return success_msg, report_content
            
        except Exception as e:
            error_msg = f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}", ""
    
    def upload_documents(self, files) -> str:
        """å¤„ç†æ–‡æ¡£ä¸Šä¼ """
        if not files:
            return "âŒ è¯·é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶"
        
        try:
            success_count = 0
            error_count = 0
            
            for file in files:
                try:
                    # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                    temp_path = Path("./temp") / file.name
                    temp_path.parent.mkdir(exist_ok=True)
                    
                    # å¤åˆ¶æ–‡ä»¶
                    shutil.copy2(file.name, temp_path)
                    
                    # ä½¿ç”¨çŸ¥è¯†åº“ç®¡ç†å™¨å¤„ç†æ–‡æ¡£
                    if hasattr(self, 'knowledge_retriever') and self.knowledge_retriever:
                        # è¿™é‡Œåº”è¯¥è°ƒç”¨æ–‡æ¡£å¤„ç†æ–¹æ³•
                        # æš‚æ—¶æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                        success_count += 1
                    else:
                        error_count += 1
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if temp_path.exists():
                        temp_path.unlink()
                        
                except Exception as e:
                    error_count += 1
                    logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤„ç†å¤±è´¥: {e}")
            
            # ç”Ÿæˆç»“æœæ¶ˆæ¯
            result_msg = ""
            if success_count > 0:
                result_msg += f"âœ… æˆåŠŸå¤„ç† {success_count} ä¸ªæ–‡æ¡£\n"
            if error_count > 0:
                result_msg += f"âŒ {error_count} ä¸ªæ–‡æ¡£å¤„ç†å¤±è´¥\n"
            
            return result_msg if result_msg else "âŒ æ–‡æ¡£ä¸Šä¼ å¤„ç†å¤±è´¥"
            
        except Exception as e:
            error_msg = f"æ–‡ä»¶ä¸Šä¼ å¤„ç†å¼‚å¸¸ï¼š{str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}"
    
    def get_knowledge_stats(self) -> str:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            knowledge_dir = Path("./data/knowledge")
            
            # ç»Ÿè®¡æ–‡æ¡£æ•°é‡
            doc_count = 0
            total_size = 0
            
            if knowledge_dir.exists():
                for ext in ['.pdf', '.docx', '.txt', '.md']:
                    files = list(knowledge_dir.rglob(f'*{ext}'))
                    doc_count += len(files)
                    total_size += sum(f.stat().st_size for f in files)
            
            stats_text = "## ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡\n\n"
            stats_text += f"**æ–‡æ¡£æ•°é‡**: {doc_count}\n"
            stats_text += f"**æ€»å¤§å°**: {total_size / 1024 / 1024:.1f} MB\n"
            
            # æ˜¾ç¤ºå‘é‡æ•°æ®åº“çŠ¶æ€
            vector_db_path = Path("./data/vector_db")
            if vector_db_path.exists():
                stats_text += "**å‘é‡æ•°æ®åº“**: âœ… å·²å»ºç«‹\n"
            else:
                stats_text += "**å‘é‡æ•°æ®åº“**: âš ï¸ æœªå»ºç«‹\n"
            
            return stats_text
            
        except Exception as e:
            error_msg = f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥ï¼š{str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}"
    
    def rebuild_knowledge_index(self) -> str:
        """é‡å»ºçŸ¥è¯†åº“ç´¢å¼•"""
        try:
            # è¿™é‡Œåº”è¯¥è°ƒç”¨çŸ¥è¯†åº“é‡å»ºæ–¹æ³•
            # æš‚æ—¶æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            time.sleep(2)
            return "âœ… çŸ¥è¯†åº“ç´¢å¼•é‡å»ºå®Œæˆ"
        except Exception as e:
            error_msg = f"é‡å»ºç´¢å¼•å¤±è´¥ï¼š{str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}"
    
    def clear_knowledge_base(self) -> str:
        """æ¸…ç©ºçŸ¥è¯†åº“"""
        try:
            knowledge_dir = Path("./data/knowledge")
            vector_db_dir = Path("./data/vector_db")
            
            # åˆ é™¤çŸ¥è¯†åº“æ–‡ä»¶
            if knowledge_dir.exists():
                shutil.rmtree(knowledge_dir)
                knowledge_dir.mkdir(parents=True, exist_ok=True)
            
            # åˆ é™¤å‘é‡æ•°æ®åº“
            if vector_db_dir.exists():
                shutil.rmtree(vector_db_dir)
                vector_db_dir.mkdir(parents=True, exist_ok=True)
            
            return "âœ… çŸ¥è¯†åº“å·²æ¸…ç©º"
        except Exception as e:
            error_msg = f"æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥ï¼š{str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}"
    
    def save_model_config(self, model_type: str, **kwargs) -> str:
        """ä¿å­˜æ¨¡å‹é…ç½®"""
        try:
            self.config.set('model.type', model_type)
            
            if model_type == 'openai':
                self.config.set('model.openai.api_key', kwargs.get('api_key', ''))
                self.config.set('model.openai.base_url', kwargs.get('base_url', 'https://api.openai.com/v1'))
                self.config.set('model.openai.model_name', kwargs.get('model_name', 'gpt-3.5-turbo'))
            elif model_type == 'local':
                self.config.set('model.local.model_path', kwargs.get('model_path', ''))
                self.config.set('model.local.device', kwargs.get('device', 'auto'))
            
            return f"âœ… {model_type} é…ç½®å·²ä¿å­˜"
        except Exception as e:
            error_msg = f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}"
    
    def save_all_config(self) -> str:
        """ä¿å­˜æ‰€æœ‰é…ç½®åˆ°æ–‡ä»¶"""
        try:
            self.config.save_config()
            return f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {self.config.config_file}"
        except Exception as e:
            error_msg = f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return f"âŒ {error_msg}"
    
    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        # è·å–é£åœºå’Œé£æœºåˆ—è¡¨
        wind_farms = list(self.config.get('business.wind_farms', {}).keys())
        
        def get_turbines(wind_farm):
            if wind_farm:
                return gr.Dropdown(
                    choices=self.config.get(f'business.wind_farms.{wind_farm}.turbines', []),
                    label="é€‰æ‹©é£æœº",
                    interactive=True
                )
            return gr.Dropdown(choices=[], label="é€‰æ‹©é£æœº", interactive=False)
        
        # åˆ›å»ºä¸»ç•Œé¢
        with gr.Blocks(title="ğŸ”§ CMSæŒ¯åŠ¨åˆ†ææŠ¥å‘Šç³»ç»Ÿ", theme=gr.themes.Soft()) as interface:
            gr.Markdown("# ğŸ”§ CMSæŒ¯åŠ¨åˆ†ææŠ¥å‘Šç³»ç»Ÿ")
            
            with gr.Tabs():
                # æ™ºèƒ½å¯¹è¯æ ‡ç­¾é¡µ
                with gr.TabItem("ğŸ’¬ æ™ºèƒ½å¯¹è¯"):
                    gr.Markdown("## ğŸ’¬ æ™ºèƒ½å¯¹è¯åŠ©æ‰‹")
                    gr.Markdown("ä¸AIåŠ©æ‰‹å¯¹è¯ï¼Œè·å–æŒ¯åŠ¨åˆ†ææŠ¥å‘Šå’ŒæŠ€æœ¯æ”¯æŒ")
                    
                    chatbot = gr.Chatbot(label="å¯¹è¯å†å²", height=400)
                    msg = gr.Textbox(
                        label="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
                        placeholder="ä¾‹å¦‚ï¼šç”Ÿæˆåèƒ½é£åœºAçš„A01é£æœºæŒ¯åŠ¨åˆ†ææŠ¥å‘Š",
                        lines=2
                    )
                    
                    with gr.Row():
                        send_btn = gr.Button("å‘é€", variant="primary")
                        clear_btn = gr.Button("æ¸…ç©ºå†å²")
                    
                    # å¿«é€Ÿé—®é¢˜æŒ‰é’®
                    gr.Markdown("### ğŸ” å¿«é€Ÿé—®é¢˜")
                    with gr.Row():
                        quick_btn1 = gr.Button("ç”ŸæˆæŒ¯åŠ¨åˆ†ææŠ¥å‘Š")
                        quick_btn2 = gr.Button("æŸ¥è¯¢è®¾å¤‡çŠ¶æ€")
                        quick_btn3 = gr.Button("åˆ†ææŒ¯åŠ¨è¶‹åŠ¿")
                        quick_btn4 = gr.Button("æ•…éšœè¯Šæ–­å»ºè®®")
                    
                    # ç»‘å®šäº‹ä»¶
                    send_btn.click(
                        self.handle_chat_message,
                        inputs=[msg, chatbot],
                        outputs=[msg, chatbot]
                    )
                    msg.submit(
                        self.handle_chat_message,
                        inputs=[msg, chatbot],
                        outputs=[msg, chatbot]
                    )
                    clear_btn.click(
                        self.clear_chat_history,
                        inputs=[chatbot],
                        outputs=[chatbot]
                    )
                    
                    # å¿«é€Ÿé—®é¢˜æŒ‰é’®äº‹ä»¶
                    quick_btn1.click(
                        lambda history: self.handle_quick_question("ç”ŸæˆæŒ¯åŠ¨åˆ†ææŠ¥å‘Š", history),
                        inputs=[chatbot],
                        outputs=[msg, chatbot]
                    )
                    quick_btn2.click(
                        lambda history: self.handle_quick_question("æŸ¥è¯¢è®¾å¤‡çŠ¶æ€", history),
                        inputs=[chatbot],
                        outputs=[msg, chatbot]
                    )
                    quick_btn3.click(
                        lambda history: self.handle_quick_question("åˆ†ææŒ¯åŠ¨è¶‹åŠ¿", history),
                        inputs=[chatbot],
                        outputs=[msg, chatbot]
                    )
                    quick_btn4.click(
                        lambda history: self.handle_quick_question("æ•…éšœè¯Šæ–­å»ºè®®", history),
                        inputs=[chatbot],
                        outputs=[msg, chatbot]
                    )
                
                # æ•°æ®åˆ†ææ ‡ç­¾é¡µ
                with gr.TabItem("ğŸ“Š æ•°æ®åˆ†æ"):
                    gr.Markdown("## ğŸ“Š æŒ¯åŠ¨æ•°æ®åˆ†æ")
                    
                    with gr.Row():
                        analysis_farm = gr.Dropdown(
                            choices=wind_farms,
                            label="é€‰æ‹©é£åœº",
                            interactive=True
                        )
                        analysis_turbine = gr.Dropdown(
                            choices=[],
                            label="é€‰æ‹©é£æœº",
                            interactive=False
                        )
                    
                    generate_data_btn = gr.Button("ğŸ“ˆ ç”ŸæˆæŒ¯åŠ¨æ•°æ®", variant="primary")
                    
                    with gr.Row():
                        with gr.Column():
                            data_overview = gr.Markdown("### æ•°æ®æ¦‚è§ˆå°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                        with gr.Column():
                            data_analysis = gr.Markdown("### åˆ†æç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                    
                    chart_info = gr.Markdown("### å›¾è¡¨ä¿¡æ¯å°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                    
                    # æ›´æ–°é£æœºé€‰æ‹©
                    analysis_farm.change(
                        get_turbines,
                        inputs=[analysis_farm],
                        outputs=[analysis_turbine]
                    )
                    
                    # ç”Ÿæˆæ•°æ®åˆ†æ
                    generate_data_btn.click(
                        self.generate_vibration_data,
                        inputs=[analysis_farm, analysis_turbine],
                        outputs=[data_overview, data_analysis, chart_info]
                    )
                
                # æŠ¥å‘Šç”Ÿæˆæ ‡ç­¾é¡µ
                with gr.TabItem("ğŸ“‹ æŠ¥å‘Šç”Ÿæˆ"):
                    gr.Markdown("## ğŸ“‹ æŠ¥å‘Šç”Ÿæˆ")
                    
                    # æ•°æ®æºé…ç½®
                    gr.Markdown("### ğŸ”§ æ•°æ®æºé…ç½®")
                    use_test_data = gr.Checkbox(
                        label="ç”Ÿæˆæµ‹è¯•æ•°æ®",
                        value=False,
                        info="å‹¾é€‰æ­¤é¡¹å°†ç”Ÿæˆæµ‹è¯•æ•°æ®è¿›è¡Œåˆ†æï¼Œä¸å‹¾é€‰åˆ™è°ƒç”¨å¤–éƒ¨APIè·å–å®é™…æ•°æ®"
                    )
                    
                    # æŠ¥å‘Šå‚æ•°è®¾ç½®
                    gr.Markdown("### ğŸ“‹ æŠ¥å‘Šå‚æ•°")
                    with gr.Row():
                        report_farm = gr.Dropdown(
                            choices=wind_farms,
                            label="é€‰æ‹©é£åœº",
                            interactive=True
                        )
                        report_turbine = gr.Dropdown(
                            choices=[],
                            label="é€‰æ‹©é£æœº",
                            interactive=False
                        )
                    
                    report_type = gr.Dropdown(
                        choices=["å®Œæ•´åˆ†ææŠ¥å‘Š", "ç®€è¦çŠ¶æ€æŠ¥å‘Š", "æ•…éšœè¯Šæ–­æŠ¥å‘Š", "è¶‹åŠ¿åˆ†ææŠ¥å‘Š"],
                        label="æŠ¥å‘Šç±»å‹",
                        value="å®Œæ•´åˆ†ææŠ¥å‘Š"
                    )
                    
                    with gr.Row():
                        start_date = gr.Textbox(
                            label="å¼€å§‹æ—¥æœŸ",
                            value=(datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
                        )
                        end_date = gr.Textbox(
                            label="ç»“æŸæ—¥æœŸ",
                            value=datetime.now().strftime("%Y-%m-%d")
                        )
                    
                    report_format = gr.Dropdown(
                        choices=self.config.get('business.report.formats', ['docx', 'pdf']),
                        label="æŠ¥å‘Šæ ¼å¼",
                        value="docx"
                    )
                    
                    generate_report_btn = gr.Button("ğŸ“„ ç”ŸæˆæŠ¥å‘Š", variant="primary")
                    
                    report_status = gr.Markdown("### æŠ¥å‘ŠçŠ¶æ€å°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                    report_content = gr.Markdown("### ç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹å°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                    
                    # æ›´æ–°é£æœºé€‰æ‹©
                    report_farm.change(
                        get_turbines,
                        inputs=[report_farm],
                        outputs=[report_turbine]
                    )
                    
                    # ç”ŸæˆæŠ¥å‘Š
                    generate_report_btn.click(
                        self.generate_report,
                        inputs=[report_farm, report_turbine, report_type, start_date, end_date, report_format, use_test_data],
                        outputs=[report_status, report_content]
                    )
                
                # çŸ¥è¯†åº“ç®¡ç†æ ‡ç­¾é¡µ
                with gr.TabItem("ğŸ“š çŸ¥è¯†åº“ç®¡ç†"):
                    gr.Markdown("## ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
                    
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown("### ğŸ“¤ ä¸Šä¼ æ–‡æ¡£")
                            upload_files = gr.File(
                                label="é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡æ¡£",
                                file_count="multiple",
                                file_types=[".pdf", ".docx", ".txt", ".md"]
                            )
                            upload_btn = gr.Button("ğŸš€ å¼€å§‹ä¸Šä¼ å¹¶å¤„ç†", variant="primary")
                            upload_status = gr.Markdown("### ä¸Šä¼ çŠ¶æ€å°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                        
                        with gr.Column():
                            knowledge_stats = gr.Markdown(self.get_knowledge_stats())
                            
                            gr.Markdown("### ğŸ”§ ç®¡ç†æ“ä½œ")
                            rebuild_btn = gr.Button("ğŸ”„ é‡å»ºçŸ¥è¯†åº“ç´¢å¼•")
                            clear_kb_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“", variant="secondary")
                            
                            operation_status = gr.Markdown("### æ“ä½œçŠ¶æ€å°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                    
                    # ç»‘å®šäº‹ä»¶
                    upload_btn.click(
                        self.upload_documents,
                        inputs=[upload_files],
                        outputs=[upload_status]
                    )
                    
                    rebuild_btn.click(
                        self.rebuild_knowledge_index,
                        outputs=[operation_status]
                    )
                    
                    clear_kb_btn.click(
                        self.clear_knowledge_base,
                        outputs=[operation_status]
                    )
                
                # ç³»ç»Ÿé…ç½®æ ‡ç­¾é¡µ
                with gr.TabItem("âš™ï¸ ç³»ç»Ÿé…ç½®"):
                    gr.Markdown("## âš™ï¸ ç³»ç»Ÿé…ç½®")
                    
                    # é…ç½®æ–‡ä»¶æ“ä½œ
                    gr.Markdown("### ğŸ“ é…ç½®æ–‡ä»¶æ“ä½œ")
                    reload_config_btn = gr.Button("ğŸ“‚ é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶")
                    config_status = gr.Markdown("### é…ç½®çŠ¶æ€å°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                    
                    # æ¨¡å‹é…ç½®
                    gr.Markdown("### ğŸ¤– æ¨¡å‹é…ç½®")
                    model_type = gr.Dropdown(
                        choices=['local', 'openai', 'deepseek_api', 'custom'],
                        label="æ¨¡å‹ç±»å‹",
                        value=self.config.get('model.type', 'local')
                    )
                    
                    # OpenAIé…ç½®
                    with gr.Group(visible=False) as openai_config:
                        api_key = gr.Textbox(
                            label="OpenAI API Key",
                            type="password",
                            value=self.config.get('model.openai.api_key', '')
                        )
                        base_url = gr.Textbox(
                            label="Base URL",
                            value=self.config.get('model.openai.base_url', 'https://api.openai.com/v1')
                        )
                        openai_model_name = gr.Textbox(
                            label="æ¨¡å‹åç§°",
                            value=self.config.get('model.openai.model_name', 'gpt-3.5-turbo')
                        )
                        save_openai_btn = gr.Button("ğŸ’¾ ä¿å­˜OpenAIé…ç½®")
                    
                    # æœ¬åœ°æ¨¡å‹é…ç½®
                    with gr.Group(visible=True) as local_config:
                        model_path = gr.Textbox(
                            label="æœ¬åœ°æ¨¡å‹è·¯å¾„",
                            value=self.config.get('model.local.model_path', '')
                        )
                        device = gr.Dropdown(
                            choices=['auto', 'cuda', 'cpu'],
                            label="è®¾å¤‡",
                            value=self.config.get('model.local.device', 'auto')
                        )
                        save_local_btn = gr.Button("ğŸ’¾ ä¿å­˜æœ¬åœ°æ¨¡å‹é…ç½®")
                    
                    save_all_btn = gr.Button("ğŸ’¾ ä¿å­˜æ‰€æœ‰é…ç½®åˆ°æ–‡ä»¶", variant="primary")
                    
                    # æ˜¾ç¤ºé…ç½®ç»„ä»¶çš„å‡½æ•°
                    def show_config_group(model_type_value):
                        return (
                            gr.Group(visible=model_type_value == 'openai'),
                            gr.Group(visible=model_type_value == 'local')
                        )
                    
                    # ç»‘å®šäº‹ä»¶
                    model_type.change(
                        show_config_group,
                        inputs=[model_type],
                        outputs=[openai_config, local_config]
                    )
                    
                    reload_config_btn.click(
                        self.reload_config,
                        outputs=[config_status]
                    )
                    
                    save_openai_btn.click(
                        lambda: self.save_model_config('openai', api_key=api_key.value, base_url=base_url.value, model_name=openai_model_name.value),
                        outputs=[config_status]
                    )
                    
                    save_local_btn.click(
                        lambda: self.save_model_config('local', model_path=model_path.value, device=device.value),
                        outputs=[config_status]
                    )
                    
                    save_all_btn.click(
                        self.save_all_config,
                        outputs=[config_status]
                    )
            
            # ä¾§è¾¹æ ä¿¡æ¯ï¼ˆä½¿ç”¨Accordionæ¨¡æ‹Ÿï¼‰
            with gr.Accordion("ğŸ›ï¸ ç³»ç»Ÿæ§åˆ¶å°", open=True):
                system_status_display = gr.Markdown(self.get_system_status_display())
                config_info_display = gr.Markdown(self.get_config_info())
                
                gr.Markdown("### ğŸš€ å¿«é€Ÿæ“ä½œ")
                with gr.Row():
                    reload_btn = gr.Button("ğŸ”„ é‡æ–°åŠ è½½é…ç½®")
                    clear_history_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²")
                    test_data_btn = gr.Button("ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®")
                
                quick_status = gr.Markdown("### æ“ä½œçŠ¶æ€å°†åœ¨è¿™é‡Œæ˜¾ç¤º")
                
                # ç»‘å®šå¿«é€Ÿæ“ä½œäº‹ä»¶
                reload_btn.click(
                    self.reload_config,
                    outputs=[quick_status]
                )
                
                test_data_btn.click(
                    self.generate_test_data,
                    outputs=[quick_status]
                )
        
        return interface


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨Gradioï¼ˆè¿™é‡Œæˆ‘ä»¬å‡è®¾æ€»æ˜¯å¯ç”¨ï¼‰
    config = get_config()
    
    # åˆ›å»ºåº”ç”¨å®ä¾‹
    app = GradioCMSApp()
    
    # åˆ›å»ºç•Œé¢
    interface = app.create_interface()
    
    # å¯åŠ¨åº”ç”¨
    interface.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,       # é»˜è®¤ç«¯å£
        share=True,             # åˆ›å»ºå…¬å…±é“¾æ¥ä»¥ä¾¿è®¿é—®
        debug=True,             # å¯ç”¨è°ƒè¯•æ¨¡å¼
        show_error=True         # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    )


if __name__ == "__main__":
    main()