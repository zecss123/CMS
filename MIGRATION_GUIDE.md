# CMSæŒ¯åŠ¨åˆ†æç³»ç»Ÿ - ç”¨æˆ·è¿ç§»æŒ‡å—

æœ¬æ–‡æ¡£æŒ‡å¯¼ç”¨æˆ·å¦‚ä½•è°ƒæ•´ç³»ç»Ÿé…ç½®ã€åˆ‡æ¢å¤§æ¨¡å‹æ¥å£ã€è¿ç§»æ•°æ®å’Œè‡ªå®šä¹‰ç³»ç»Ÿå‚æ•°ã€‚

## ç›®å½•

- [æ–°æ‰‹å¿«é€Ÿå…¥é—¨](#æ–°æ‰‹å¿«é€Ÿå…¥é—¨)
- [é…ç½®æ–‡ä»¶è¯´æ˜](#é…ç½®æ–‡ä»¶è¯´æ˜)
- [å¤§æ¨¡å‹æ¥å£é…ç½®](#å¤§æ¨¡å‹æ¥å£é…ç½®)
- [APIæ¥å£è°ƒæ•´](#apiæ¥å£è°ƒæ•´)
- [æ•°æ®åº“è¿ç§»](#æ•°æ®åº“è¿ç§»)
- [çŸ¥è¯†åº“è¿ç§»](#çŸ¥è¯†åº“è¿ç§»)
- [æ¨¡æ¿è‡ªå®šä¹‰](#æ¨¡æ¿è‡ªå®šä¹‰)
- [æ€§èƒ½å‚æ•°è°ƒä¼˜](#æ€§èƒ½å‚æ•°è°ƒä¼˜)
- [ç¯å¢ƒå˜é‡é…ç½®](#ç¯å¢ƒå˜é‡é…ç½®)
- [å¸¸è§è¿ç§»åœºæ™¯](#å¸¸è§è¿ç§»åœºæ™¯)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## æ–°æ‰‹å¿«é€Ÿå…¥é—¨

### ğŸš€ æˆ‘æƒ³è¦åšä»€ä¹ˆï¼Ÿ

#### 1. æˆ‘æƒ³æ¢ä¸ªå¤§æ¨¡å‹ï¼ˆæ¯”å¦‚ä»OpenAIæ¢åˆ°DeepSeekï¼‰

**æ­¥éª¤ï¼š**
1. æ‰“å¼€ `config.yaml` æ–‡ä»¶
2. æ‰¾åˆ° `llm:` éƒ¨åˆ†
3. ä¿®æ”¹ `provider: "deepseek"` 
4. åœ¨ `deepseek:` éƒ¨åˆ†å¡«å…¥ä½ çš„APIå¯†é’¥
5. é‡å¯åº”ç”¨

**å®Œæ•´ç¤ºä¾‹ï¼š**
```yaml
llm:
  provider: "deepseek"  # æ”¹è¿™é‡Œ
  deepseek:
    api_key: "sk-ä½ çš„deepseekå¯†é’¥"  # æ”¹è¿™é‡Œ
    base_url: "https://api.deepseek.com/v1"
    model: "deepseek-chat"
    temperature: 0.7
    max_tokens: 2048
```

**âš ï¸ æ³¨æ„äº‹é¡¹ï¼š**
- ä¿®æ”¹åéœ€è¦é‡å¯æ‰€æœ‰åº”ç”¨ï¼ˆStreamlitã€Gradioã€APIæœåŠ¡å™¨ï¼‰
- ç¡®ä¿ä½ æœ‰å¯¹åº”å¹³å°çš„APIå¯†é’¥
- ä¸åŒæ¨¡å‹çš„å“åº”æ ¼å¼å¯èƒ½ç•¥æœ‰å·®å¼‚

#### 2. æˆ‘æƒ³å¯åŠ¨ç½‘é¡µç•Œé¢

**Streamlitç•Œé¢ï¼ˆæ¨èæ–°æ‰‹ï¼‰ï¼š**
```bash
cd /path/to/cms_vibration_rag
python -m streamlit run streamlit_app.py
```
è®¿é—®ï¼šhttp://localhost:8501

**Gradioç•Œé¢ï¼š**
```bash
cd /path/to/cms_vibration_rag
python gradio_app.py
```
è®¿é—®ï¼šhttp://localhost:7860

**âš ï¸ å¯åŠ¨å‰æ£€æŸ¥ï¼š**
- ç¡®ä¿ `config.yaml` ä¸­æ¨¡å‹é…ç½®æ­£ç¡®
- ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®
- ç¡®ä¿ä¾èµ–åŒ…å·²å®‰è£…ï¼š`pip install -r requirements.txt`

#### 3. æˆ‘æƒ³å¯åŠ¨APIæœåŠ¡å™¨

**å¯åŠ¨APIæœåŠ¡å™¨ï¼š**
```bash
cd /path/to/cms_vibration_rag
python api/main.py
```

**APIæ–‡æ¡£åœ°å€ï¼š**
- Swaggeræ–‡æ¡£ï¼šhttp://localhost:8000/docs
- ReDocæ–‡æ¡£ï¼šhttp://localhost:8000/redoc

**æµ‹è¯•APIï¼š**
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# èŠå¤©æ¥å£æµ‹è¯•
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "ä½ å¥½", "session_id": "test"}'
```

#### 4. æˆ‘æƒ³ä¿®æ”¹æ•°æ®åº“é…ç½®

**ä»SQLiteæ¢åˆ°PostgreSQLï¼š**

1. **å®‰è£…PostgreSQLä¾èµ–ï¼š**
```bash
pip install psycopg2-binary
```

2. **ä¿®æ”¹config.yamlï¼š**
```yaml
vector_db:
  provider: "chromadb"  # æˆ–è€… "pinecone"
  chromadb:
    persist_directory: "./data/vector_db"
    collection_name: "cms_knowledge"
```

3. **é‡æ–°åˆå§‹åŒ–æ•°æ®åº“ï¼š**
```bash
python -c "
from knowledge.knowledge_manager import KnowledgeManager
km = KnowledgeManager()
km.initialize_database()
print('æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ')
"
```

**âš ï¸ é…å¥—ä¿®æ”¹ï¼š**
- ç¡®ä¿æ•°æ®åº“æœåŠ¡å·²å¯åŠ¨
- ç¡®ä¿æ•°æ®åº“å’Œç”¨æˆ·å·²åˆ›å»º
- å¤‡ä»½åŸæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰

### ğŸ”§ å¸¸è§é…ç½®ä¿®æ”¹

#### ä¿®æ”¹æ—¥å¿—çº§åˆ«
```yaml
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "cms_system.log"
```

#### ä¿®æ”¹å¤„ç†çº¿ç¨‹æ•°
```yaml
processing:
  max_workers: 4  # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
  batch_size: 100  # æ ¹æ®å†…å­˜å¤§å°è°ƒæ•´
```

#### å¯ç”¨/ç¦ç”¨ç¼“å­˜
```yaml
processing:
  cache_enabled: true  # trueå¯ç”¨ï¼Œfalseç¦ç”¨
  cache_ttl: 3600
```

## ç³»ç»Ÿé…ç½®

### ğŸ“ æ—¥å¿—é…ç½®ï¼ˆè°ƒè¯•å’Œç›‘æ§ï¼‰

**æˆ‘æƒ³è°ƒæ•´æ—¥å¿—çº§åˆ«å’Œè¾“å‡ºï¼š**

**å¼€å‘ç¯å¢ƒï¼ˆè¯¦ç»†æ—¥å¿—ï¼‰ï¼š**
```yaml
logging:
  level: "DEBUG"  # æ˜¾ç¤ºæ‰€æœ‰è°ƒè¯•ä¿¡æ¯
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  handlers:
    - type: "console"  # æ§åˆ¶å°è¾“å‡º
      level: "DEBUG"
    - type: "file"
      filename: "logs/cms_vibration_debug.log"
      level: "DEBUG"
      max_bytes: 10485760  # 10MB
      backup_count: 5
```

**ç”Ÿäº§ç¯å¢ƒï¼ˆç²¾ç®€æ—¥å¿—ï¼‰ï¼š**
```yaml
logging:
  level: "INFO"  # åªæ˜¾ç¤ºé‡è¦ä¿¡æ¯
  format: "%(asctime)s - %(levelname)s - %(message)s"
  handlers:
    - type: "file"
      filename: "logs/cms_vibration.log"
      level: "INFO"
      max_bytes: 52428800  # 50MB
      backup_count: 10
```

**âš ï¸ æ—¥å¿—é…ç½®é…å¥—ä¿®æ”¹ï¼š**
1. åˆ›å»ºæ—¥å¿—ç›®å½•ï¼š
   ```bash
   mkdir -p logs
   ```
2. è®¾ç½®æ—¥å¿—æ–‡ä»¶æƒé™ï¼š
   ```bash
   chmod 755 logs
   ```
3. é‡å¯åº”ç”¨ä»¥åº”ç”¨æ–°é…ç½®
4. ç›‘æ§æ—¥å¿—æ–‡ä»¶å¤§å°ï¼Œé¿å…ç£ç›˜ç©ºé—´ä¸è¶³

### ğŸš€ ç¼“å­˜é…ç½®ï¼ˆæå‡æ€§èƒ½ï¼‰

**æˆ‘æƒ³é…ç½®ç¼“å­˜ç³»ç»Ÿï¼š**

**é€‰é¡¹1ï¼šå†…å­˜ç¼“å­˜ï¼ˆç®€å•ï¼Œé€‚åˆå•æœºï¼‰**
```yaml
cache:
  type: "memory"
  config:
    max_size: 1000  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
    ttl: 3600  # é»˜è®¤è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
```

**é€‰é¡¹2ï¼šRedisç¼“å­˜ï¼ˆæ¨èï¼Œæ”¯æŒåˆ†å¸ƒå¼ï¼‰**
```yaml
cache:
  type: "redis"
  config:
    host: "localhost"  # RedisæœåŠ¡å™¨åœ°å€
    port: 6379
    db: 0  # æ•°æ®åº“ç¼–å·
    password: null  # å¦‚æœæœ‰å¯†ç åˆ™å¡«å†™
    ttl: 3600  # é»˜è®¤è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
    max_connections: 10
```

**âš ï¸ Redisç¼“å­˜é…å¥—ä¿®æ”¹ï¼š**
1. å®‰è£…RedisæœåŠ¡å™¨ï¼š
   ```bash
   # Ubuntu/Debian
   sudo apt-get install redis-server
   
   # CentOS/RHEL
   sudo yum install redis
   
   # æˆ–ä½¿ç”¨Docker
   docker run -d --name redis -p 6379:6379 redis:latest
   ```

2. å®‰è£…Python Rediså®¢æˆ·ç«¯ï¼š
   ```bash
   pip install redis
   ```

3. å¯åŠ¨RedisæœåŠ¡ï¼š
   ```bash
   sudo systemctl start redis
   sudo systemctl enable redis
   ```

4. æµ‹è¯•Redisè¿æ¥ï¼š
   ```bash
   redis-cli ping
   # æœŸæœ›è¿”å›ï¼šPONG
   ```

### âš¡ æ€§èƒ½é…ç½®

**æˆ‘æƒ³ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼š**

```yaml
performance:
  # å¹¶å‘é…ç½®
  max_workers: 4  # å·¥ä½œè¿›ç¨‹æ•°ï¼ˆå»ºè®®ä¸ºCPUæ ¸å¿ƒæ•°ï¼‰
  max_concurrent_requests: 100  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
  
  # å†…å­˜é…ç½®
  max_memory_usage: "2GB"  # æœ€å¤§å†…å­˜ä½¿ç”¨é‡
  gc_threshold: 0.8  # åƒåœ¾å›æ”¶é˜ˆå€¼
  
  # è¶…æ—¶é…ç½®
  request_timeout: 30  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
  llm_timeout: 60  # LLMè°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
  db_timeout: 10  # æ•°æ®åº“æŸ¥è¯¢è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
```

**âš ï¸ æ€§èƒ½ä¼˜åŒ–é…å¥—ä¿®æ”¹ï¼š**
1. ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨ï¼š
   ```bash
   # æŸ¥çœ‹CPUå’Œå†…å­˜ä½¿ç”¨
   htop
   
   # æŸ¥çœ‹è¿›ç¨‹çŠ¶æ€
   ps aux | grep python
   ```

2. è°ƒæ•´ç³»ç»Ÿé™åˆ¶ï¼š
   ```bash
   # å¢åŠ æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
   ulimit -n 65536
   ```

3. é‡å¯åº”ç”¨ä»¥åº”ç”¨æ–°é…ç½®

### ğŸ”’ å®‰å…¨é…ç½®

**æˆ‘æƒ³åŠ å¼ºç³»ç»Ÿå®‰å…¨ï¼š**

```yaml
security:
  # APIå®‰å…¨
  enable_cors: true  # å¯ç”¨è·¨åŸŸè¯·æ±‚
  allowed_origins:
    - "http://localhost:3000"
    - "https://yourdomain.com"
  
  # è¯·æ±‚é™åˆ¶
  rate_limit:
    enabled: true
    requests_per_minute: 60  # æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°
    burst_size: 10  # çªå‘è¯·æ±‚æ•°
  
  # æ–‡ä»¶ä¸Šä¼ å®‰å…¨
  upload:
    max_file_size: "10MB"  # æœ€å¤§æ–‡ä»¶å¤§å°
    allowed_extensions: [".pdf", ".txt", ".docx"]  # å…è®¸çš„æ–‡ä»¶ç±»å‹
    scan_uploads: true  # æ‰«æä¸Šä¼ æ–‡ä»¶
```

**âš ï¸ å®‰å…¨é…ç½®é…å¥—ä¿®æ”¹ï¼š**
1. å®‰è£…å®‰å…¨ç›¸å…³ä¾èµ–ï¼š
   ```bash
   pip install python-multipart aiofiles
   ```

2. é…ç½®é˜²ç«å¢™è§„åˆ™ï¼š
   ```bash
   # åªå…è®¸å¿…è¦ç«¯å£
   sudo ufw allow 8000/tcp  # APIç«¯å£
   sudo ufw allow 8501/tcp  # Streamlitç«¯å£
   ```

3. å®šæœŸæ›´æ–°ä¾èµ–åŒ…ï¼š
   ```bash
   pip list --outdated
   pip install --upgrade package_name
   ```

### ğŸ“‹ ä¿®æ”¹å‚æ•°åçš„æ£€æŸ¥æ¸…å•

**ä¿®æ”¹å¤§æ¨¡å‹åï¼š**
- [ ] é‡å¯æ‰€æœ‰åº”ç”¨
- [ ] æµ‹è¯•èŠå¤©åŠŸèƒ½
- [ ] æ£€æŸ¥æ—¥å¿—æ˜¯å¦æœ‰é”™è¯¯
- [ ] éªŒè¯APIå“åº”æ ¼å¼

**ä¿®æ”¹æ•°æ®åº“åï¼š**
- [ ] è¿è¡Œæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
- [ ] æµ‹è¯•æ•°æ®è¯»å†™
- [ ] å¤‡ä»½åŸæ•°æ®
- [ ] æ£€æŸ¥è¿æ¥é…ç½®

**ä¿®æ”¹APIé…ç½®åï¼š**
- [ ] é‡å¯APIæœåŠ¡å™¨
- [ ] æµ‹è¯•APIç«¯ç‚¹
- [ ] æ£€æŸ¥è®¤è¯é…ç½®
- [ ] éªŒè¯å“åº”æ ¼å¼

### ğŸ†˜ å‡ºé—®é¢˜äº†æ€ä¹ˆåŠï¼Ÿ

**å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆï¼š**

1. **"APIå¯†é’¥æ— æ•ˆ"**
   - æ£€æŸ¥ `config.yaml` ä¸­çš„APIå¯†é’¥æ˜¯å¦æ­£ç¡®
   - ç¡®è®¤å¯†é’¥æ ¼å¼ï¼ˆé€šå¸¸ä»¥ `sk-` å¼€å¤´ï¼‰
   - æ£€æŸ¥ç½‘ç»œè¿æ¥

2. **"æ¨¡å—æœªæ‰¾åˆ°"**
   ```bash
   pip install -r requirements.txt
   ```

3. **"å‘é‡æ•°æ®åº“è¿æ¥å¤±è´¥"**
   - æ£€æŸ¥å‘é‡æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨
   - éªŒè¯è¿æ¥å‚æ•°
   - é‡æ–°åˆå§‹åŒ–æ•°æ®åº“

4. **"ç«¯å£è¢«å ç”¨"**
   ```bash
   # æŸ¥çœ‹ç«¯å£å ç”¨
   lsof -i :8501  # Streamlit
   lsof -i :7860  # Gradio
   lsof -i :8000  # APIæœåŠ¡å™¨
   
   # æ€æ­»è¿›ç¨‹
   kill -9 <è¿›ç¨‹ID>
   ```

5. **"å†…å­˜ä¸è¶³"**
   - å¯ç”¨æ¨¡å‹é‡åŒ–ï¼š`load_in_4bit: true`
   - å‡å°‘æ‰¹å¤„ç†å¤§å°ï¼š`batch_size: 16`
   - å‡å°‘æœ€å¤§workeræ•°ï¼š`max_workers: 2`

## é…ç½®æ–‡ä»¶è¯´æ˜

### ä¸»é…ç½®æ–‡ä»¶ (config.yaml)

ç³»ç»Ÿçš„æ ¸å¿ƒé…ç½®æ–‡ä»¶ä½äºé¡¹ç›®æ ¹ç›®å½•ï¼š

```yaml
# CMSæŒ¯åŠ¨åˆ†æç³»ç»Ÿé…ç½®æ–‡ä»¶
api:
  # CMSæ•°æ®APIé…ç½®
  cms_base_url: "http://172.16.253.39/api/model/services"
  timeout: 30
  retry_times: 3
  retry_delay: 1
  
  # è®¤è¯é…ç½®
  auth_token: "your_auth_token_here"
  api_key: "your_api_key_here"

# å¤§è¯­è¨€æ¨¡å‹é…ç½®
llm:
  # æ¨¡å‹æä¾›å•†: openai, deepseek, qwen, local
  provider: "deepseek"
  
  # OpenAIé…ç½®
  openai:
    api_key: "sk-your-openai-key"
    base_url: "https://api.openai.com/v1"
    model: "gpt-4"
    temperature: 0.7
    max_tokens: 2048
  
  # DeepSeeké…ç½®
  deepseek:
    api_key: "sk-your-deepseek-key"
    base_url: "https://api.deepseek.com/v1"
    model: "deepseek-chat"
    temperature: 0.7
    max_tokens: 2048
  
  # é€šä¹‰åƒé—®é…ç½®
  qwen:
    api_key: "sk-your-qwen-key"
    base_url: "https://dashscope.aliyuncs.com/api/v1"
    model: "qwen-turbo"
    temperature: 0.7
    max_tokens: 2048
  
  # æœ¬åœ°æ¨¡å‹é…ç½®
  local:
    model_path: "/root/autodl-tmp/models/deepseek-7b"
    device: "cuda"
    max_memory: "8GB"
    load_in_8bit: false
    load_in_4bit: true

# åµŒå…¥æ¨¡å‹é…ç½®
embedding:
  # æ¨¡å‹ç±»å‹: sentence_transformers, openai, local
  provider: "sentence_transformers"
  
  # SentenceTransformersé…ç½®
  sentence_transformers:
    model_name: "all-MiniLM-L6-v2"
    device: "cuda"
    batch_size: 32
  
  # OpenAIåµŒå…¥é…ç½®
  openai:
    api_key: "sk-your-openai-key"
    model: "text-embedding-ada-002"
  
  # æœ¬åœ°åµŒå…¥æ¨¡å‹
  local:
    model_path: "/root/autodl-tmp/models/embeddings/bge-large-zh"
    device: "cuda"

# å‘é‡æ•°æ®åº“é…ç½®
vector_db:
  # æ•°æ®åº“ç±»å‹: chromadb, faiss, pinecone
  provider: "chromadb"
  
  # ChromaDBé…ç½®
  chromadb:
    persist_directory: "./data/vector_db"
    collection_name: "cms_knowledge"
  
  # Pineconeé…ç½®
  pinecone:
    api_key: "your-pinecone-key"
    environment: "us-west1-gcp"
    index_name: "cms-vibration"

# æ•°æ®å¤„ç†é…ç½®
processing:
  # å¹¶å‘å¤„ç†
  max_workers: 4
  batch_size: 100
  
  # ç¼“å­˜é…ç½®
  cache_enabled: true
  cache_ttl: 3600
  cache_dir: "./cache"
  
  # å†…å­˜ç®¡ç†
  max_memory_usage: "6GB"
  gc_threshold: 0.8

# æ—¥å¿—é…ç½®
logging:
  level: "INFO"
  file: "cms_system.log"
  max_size: "10MB"
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# è¾“å‡ºé…ç½®
output:
  # é»˜è®¤è¾“å‡ºæ ¼å¼
  default_format: "json"
  
  # æŠ¥å‘Šé…ç½®
  reports:
    template_dir: "./report_templates"
    output_dir: "./output"
    include_charts: true
    chart_format: "png"
    chart_dpi: 300
  
  # å›¾è¡¨é…ç½®
  charts:
    font_family: "SimHei"
    figure_size: [12, 8]
    color_scheme: "default"
    style: "seaborn"
```

### åº”ç”¨ç‰¹å®šé…ç½®

#### Streamlité…ç½® (.streamlit/config.toml)
```toml
[server]
port = 8501
headless = true
enableCORS = false
enableXsrfProtection = false

[theme]
primaryColor = "#FF6B6B"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
```

#### Gradioé…ç½®
```python
# åœ¨gradio_app.pyä¸­ä¿®æ”¹
import gradio as gr

# åŸºç¡€é…ç½®
GRADIO_CONFIG = {
    "server_name": "0.0.0.0",
    "server_port": 7860,
    "share": False,
    "debug": False,
    "auth": None,  # æˆ– ("username", "password")
    "ssl_keyfile": None,
    "ssl_certfile": None,
    "ssl_keyfile_password": None
}
```

## å¤§æ¨¡å‹æ¥å£é…ç½®

### ğŸ”„ APIç‰ˆæœ¬å…¼å®¹æ€§è¯´æ˜

**é‡è¦æé†’ï¼š** ä¿®æ”¹å¤§æ¨¡å‹é…ç½®ä¸ä¼šå½±å“APIæœåŠ¡å™¨çš„ç‰ˆæœ¬å’Œæ¥å£æ ¼å¼ã€‚APIæœåŠ¡å™¨ä½œä¸ºä¸­é—´å±‚ï¼Œä¼šè‡ªåŠ¨é€‚é…ä¸åŒçš„å¤§æ¨¡å‹æä¾›å•†ï¼Œå¯¹å¤–æä¾›ç»Ÿä¸€çš„æ¥å£æ ¼å¼ã€‚

**APIå…¼å®¹æ€§ä¿è¯ï¼š**
- âœ… èŠå¤©æ¥å£ `/chat` æ ¼å¼ä¿æŒä¸å˜
- âœ… æŠ¥å‘Šç”Ÿæˆæ¥å£ `/generate_report` æ ¼å¼ä¿æŒä¸å˜
- âœ… çŸ¥è¯†æ£€ç´¢æ¥å£ `/search` æ ¼å¼ä¿æŒä¸å˜
- âœ… å®¢æˆ·ç«¯ä»£ç æ— éœ€ä¿®æ”¹

### 1. åˆ‡æ¢åˆ°OpenAI

**é…ç½®æ–‡ä»¶æ–¹å¼ï¼š**
```yaml
# åœ¨config.yamlä¸­ä¿®æ”¹
model:
  type: "openai"  # å…³é”®é…ç½®
  openai:
    api_key: "sk-your-openai-api-key"  # å¿…é¡»ä¿®æ”¹
    base_url: "https://api.openai.com/v1"
    model: "gpt-4"  # å¯é€‰ï¼šgpt-3.5-turbo, gpt-4, gpt-4-turbo
    temperature: 0.7  # åˆ›é€ æ€§ï¼š0-2ï¼Œè¶Šé«˜è¶Šæœ‰åˆ›æ„
    max_tokens: 2048  # æœ€å¤§è¾“å‡ºé•¿åº¦
```

**ç¯å¢ƒå˜é‡æ–¹å¼ï¼š**
```bash
# åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®
CMS_MODEL_TYPE=openai
CMS_OPENAI_API_KEY=sk-your-openai-api-key
CMS_OPENAI_BASE_URL=https://api.openai.com/v1
```

**âš ï¸ é…å¥—ä¿®æ”¹æ¸…å•ï¼š**
1. ç¡®ä¿ç½‘ç»œèƒ½è®¿é—®OpenAI API
2. æ£€æŸ¥APIå¯†é’¥ä½™é¢
3. é‡å¯æ‰€æœ‰æœåŠ¡ï¼š
   ```bash
   # é‡å¯Streamlit
   pkill -f streamlit
   python streamlit_app.py
   
   # é‡å¯APIæœåŠ¡å™¨
   pkill -f "python.*api"
   python start_api_server.py
   ```
4. æµ‹è¯•èŠå¤©åŠŸèƒ½æ˜¯å¦æ­£å¸¸

### 2. åˆ‡æ¢åˆ°DeepSeek

**é…ç½®æ–‡ä»¶æ–¹å¼ï¼š**
```yaml
model:
  type: "deepseek_api"  # å…³é”®é…ç½®
  deepseek_api:
    api_key: "sk-your-deepseek-key"  # å¿…é¡»ä¿®æ”¹
    base_url: "https://api.deepseek.com/v1"
    model: "deepseek-chat"  # æ¨èæ¨¡å‹
    temperature: 0.7
    max_tokens: 2048
```

**ç¯å¢ƒå˜é‡æ–¹å¼ï¼š**
```bash
# åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®
CMS_MODEL_TYPE=deepseek_api
CMS_DEEPSEEK_API_KEY=sk-your-deepseek-key
```

**âš ï¸ DeepSeekç‰¹æ®Šè¯´æ˜ï¼š**
- DeepSeek APIç›¸å¯¹ä¾¿å®œï¼Œé€‚åˆå¤§é‡ä½¿ç”¨
- æ”¯æŒä¸­æ–‡å¯¹è¯ï¼Œæ•ˆæœè¾ƒå¥½
- éœ€è¦ç§‘å­¦ä¸Šç½‘è®¿é—®ï¼ˆéƒ¨åˆ†åœ°åŒºï¼‰

**é…å¥—ä¿®æ”¹ï¼š**
1. æ³¨å†ŒDeepSeekè´¦å·è·å–APIå¯†é’¥
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. é‡å¯æœåŠ¡å¹¶æµ‹è¯•

### 3. ä½¿ç”¨æœ¬åœ°æ¨¡å‹

**é…ç½®æ–‡ä»¶æ–¹å¼ï¼š**
```yaml
model:
  type: "local"  # å…³é”®é…ç½®
  local:
    model_path: "/root/autodl-tmp/models/deepseek-7b"  # æ¨¡å‹è·¯å¾„
    device: "cuda"  # GPUåŠ é€Ÿï¼ŒCPUç”¨"cpu"
    max_memory: "8GB"  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
    load_in_8bit: false
    load_in_4bit: true  # 4bité‡åŒ–èŠ‚çœå†…å­˜
    trust_remote_code: true
```

**âš ï¸ æœ¬åœ°æ¨¡å‹ç‰¹æ®Šè¯´æ˜ï¼š**
- éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆé€šå¸¸å‡ GBåˆ°å‡ åGBï¼‰
- éœ€è¦è¶³å¤Ÿçš„æ˜¾å­˜ï¼ˆæ¨è8GBä»¥ä¸Šï¼‰
- é¦–æ¬¡åŠ è½½è¾ƒæ…¢ï¼Œåç»­ä½¿ç”¨å¿«
- æ— éœ€ç½‘ç»œè¿æ¥

**é…å¥—ä¿®æ”¹æ¸…å•ï¼š**
1. **ä¸‹è½½æ¨¡å‹ï¼š**
   ```bash
   # ä½¿ç”¨huggingface-cliä¸‹è½½
   pip install huggingface_hub
   huggingface-cli download deepseek-ai/deepseek-llm-7b-chat --local-dir /root/autodl-tmp/models/deepseek-7b
   ```

2. **æ£€æŸ¥æ˜¾å­˜ï¼š**
   ```bash
   nvidia-smi  # æŸ¥çœ‹GPUæ˜¾å­˜
   ```

3. **è°ƒæ•´é‡åŒ–è®¾ç½®ï¼š**
   - æ˜¾å­˜ä¸è¶³æ—¶å¯ç”¨ï¼š`load_in_4bit: true`
   - æ˜¾å­˜å……è¶³æ—¶ç¦ç”¨ï¼š`load_in_4bit: false`

4. **æµ‹è¯•åŠ è½½ï¼š**
   ```bash
   python -c "
   from chat.llm_client import LLMClient
   from config.config_loader import get_config
   config = get_config()
   client = LLMClient(config.get_model_config())
   print('æ¨¡å‹åŠ è½½æˆåŠŸ')
   "
   ```

### 4. ä½¿ç”¨è‡ªå®šä¹‰API

**é…ç½®æ–‡ä»¶æ–¹å¼ï¼š**
```yaml
model:
  type: "custom"  # å…³é”®é…ç½®
  custom:
    api_key: "your-custom-api-key"  # å¿…é¡»ä¿®æ”¹
    base_url: "https://your-api.com/v1"  # å¿…é¡»ä¿®æ”¹
    model: "your-model-name"
    temperature: 0.7
    max_tokens: 2048
```

**é€‚ç”¨åœºæ™¯ï¼š**
- ä¼ä¸šå†…éƒ¨API
- å…¶ä»–å…¼å®¹OpenAIæ ¼å¼çš„API
- ä»£ç†æœåŠ¡

**é…å¥—ä¿®æ”¹ï¼š**
1. ç¡®è®¤APIæ ¼å¼å…¼å®¹OpenAI
2. æµ‹è¯•APIè¿é€šæ€§
3. éªŒè¯è®¤è¯æ–¹å¼

**ä»£ç ä¸­çš„è°ƒæ•´ï¼š**

åœ¨ `chat/llm_client.py` ä¸­æ·»åŠ æ–°çš„æ¨¡å‹æ”¯æŒï¼š

```python
class LLMClient:
    def __init__(self, config):
        self.config = config
        self.provider = config['llm']['provider']
        
        if self.provider == "openai":
            self._init_openai()
        elif self.provider == "deepseek":
            self._init_deepseek()
        elif self.provider == "qwen":
            self._init_qwen()
        elif self.provider == "local":
            self._init_local_model()
    
    def _init_openai(self):
        import openai
        openai_config = self.config['llm']['openai']
        self.client = openai.OpenAI(
            api_key=openai_config['api_key'],
            base_url=openai_config.get('base_url')
        )
    
    def _init_deepseek(self):
        import openai
        deepseek_config = self.config['llm']['deepseek']
        self.client = openai.OpenAI(
            api_key=deepseek_config['api_key'],
            base_url=deepseek_config['base_url']
        )
    
    def _init_local_model(self):
        from transformers import AutoTokenizer, AutoModelForCausalLM
        local_config = self.config['llm']['local']
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            local_config['model_path'],
            trust_remote_code=local_config.get('trust_remote_code', True)
        )
        
        self.model = AutoModelForCausalLM.from_pretrained(
            local_config['model_path'],
            device_map="auto",
            max_memory={0: local_config.get('max_memory', '8GB')},
            load_in_8bit=local_config.get('load_in_8bit', False),
            load_in_4bit=local_config.get('load_in_4bit', True),
            trust_remote_code=local_config.get('trust_remote_code', True)
        )
```

## APIæ¥å£è°ƒæ•´

### ğŸ”§ å¤–éƒ¨APIé…ç½®ï¼ˆè¿æ¥CMSç³»ç»Ÿï¼‰

**æˆ‘æƒ³è¿æ¥åˆ°CMSç³»ç»Ÿè·å–çœŸå®æ•°æ®ï¼š**

1. **ä¿®æ”¹config.yamlï¼š**
```yaml
external_api:
  enabled: true  # å¯ç”¨å¤–éƒ¨API
  cms_api:
    base_url: "http://172.16.253.39/api/model/services"  # CMSç³»ç»Ÿåœ°å€
    api_key: "your_cms_api_key"  # å¿…é¡»ä¿®æ”¹
    timeout: 30
    retry_count: 3
```

2. **ç¯å¢ƒå˜é‡æ–¹å¼ï¼š**
```bash
# åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®
CMS_EXTERNAL_API_ENABLED=true
CMS_CMS_API_KEY=your_cms_api_key
CMS_CMS_API_URL=http://172.16.253.39/api/model/services
```

**âš ï¸ é…å¥—ä¿®æ”¹æ¸…å•ï¼š**
1. ç¡®ä¿ç½‘ç»œèƒ½è®¿é—®CMSç³»ç»Ÿ
2. è·å–æœ‰æ•ˆçš„APIå¯†é’¥
3. æµ‹è¯•APIè¿é€šæ€§ï¼š
   ```bash
   curl -H "Authorization: Bearer your_api_key" \
        "http://172.16.253.39/api/model/services/health"
   ```
4. é‡å¯APIæœåŠ¡å™¨

### ğŸš€ å¯åŠ¨APIæœåŠ¡å™¨çš„ä¸åŒæ–¹å¼

**æ–¹å¼1ï¼šç›´æ¥å¯åŠ¨ï¼ˆæ¨èæ–°æ‰‹ï¼‰**
```bash
cd /root/autodl-tmp/cms_vibration_rag
python start_api_server.py
```

**æ–¹å¼2ï¼šä½¿ç”¨FastAPIå‘½ä»¤**
```bash
cd /root/autodl-tmp/cms_vibration_rag
uvicorn cms_api_server:app --host 0.0.0.0 --port 8000 --reload
```

**æ–¹å¼3ï¼šåå°è¿è¡Œ**
```bash
cd /root/autodl-tmp/cms_vibration_rag
nohup python start_api_server.py > api.log 2>&1 &
```

### ğŸ“¡ APIæ¥å£è¯´æ˜

**æ ¸å¿ƒæ¥å£åˆ—è¡¨ï¼š**

| æ¥å£è·¯å¾„ | æ–¹æ³• | åŠŸèƒ½ | æ˜¯å¦éœ€è¦è®¤è¯ |
|---------|------|------|-------------|
| `/health` | GET | å¥åº·æ£€æŸ¥ | âŒ |
| `/chat` | POST | æ™ºèƒ½å¯¹è¯ | âŒ |
| `/generate_report` | POST | ç”ŸæˆæŠ¥å‘Š | âŒ |
| `/search` | POST | çŸ¥è¯†æ£€ç´¢ | âŒ |
| `/upload` | POST | æ–‡ä»¶ä¸Šä¼  | âŒ |

**æ¥å£æµ‹è¯•ç¤ºä¾‹ï¼š**

1. **å¥åº·æ£€æŸ¥ï¼š**
```bash
curl http://localhost:8000/health
# æœŸæœ›è¿”å›ï¼š{"status": "healthy"}
```

2. **æ™ºèƒ½å¯¹è¯ï¼š**
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "åˆ†æä¸€ä¸‹1å·é£æœºçš„æŒ¯åŠ¨æƒ…å†µ",
    "session_id": "test_session"
  }'
```

3. **ç”ŸæˆæŠ¥å‘Šï¼š**
```bash
curl -X POST "http://localhost:8000/generate_report" \
  -H "Content-Type: application/json" \
  -d '{
    "equipment_id": "WTG001",
    "report_type": "comprehensive",
    "time_range": {
      "start": "2024-01-01",
      "end": "2024-01-31"
    }
  }'
```

### ğŸ”Œ æ·»åŠ æ–°çš„APIç«¯ç‚¹

**å¦‚æœä½ æƒ³æ·»åŠ è‡ªå®šä¹‰APIæ¥å£ï¼š**

1. **åœ¨cms_api_server.pyä¸­æ·»åŠ ï¼š**
```python
@app.post("/custom/analysis")
async def custom_analysis(request: dict):
    """è‡ªå®šä¹‰åˆ†ææ¥å£"""
    try:
        # ä½ çš„è‡ªå®šä¹‰é€»è¾‘
        result = await perform_custom_analysis(request)
        return {"status": "success", "data": result}
    except Exception as e:
        return {"status": "error", "message": str(e)}
```

2. **é‡å¯APIæœåŠ¡å™¨ï¼š**
```bash
pkill -f "python.*api"
python start_api_server.py
```

3. **æµ‹è¯•æ–°æ¥å£ï¼š**
```bash
curl -X POST "http://localhost:8000/custom/analysis" \
  -H "Content-Type: application/json" \
  -d '{"data": "test"}'
```

**âš ï¸ APIä¿®æ”¹æ³¨æ„äº‹é¡¹ï¼š**
- ä¿®æ”¹APIåéœ€è¦é‡å¯æœåŠ¡å™¨
- æ–°æ¥å£ä¼šè‡ªåŠ¨å‡ºç°åœ¨Swaggeræ–‡æ¡£ä¸­
- ä¿æŒæ¥å£æ ¼å¼çš„ä¸€è‡´æ€§
- æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†

### CMSæ•°æ®APIé…ç½®

ä¿®æ”¹ `api/real_cms_client.py`ï¼š

```python
class RealCMSClient:
    def __init__(self, config=None):
        if config:
            self.base_url = config['api']['cms_base_url']
            self.auth_token = config['api']['auth_token']
            self.timeout = config['api']['timeout']
        else:
            # ä»ç¯å¢ƒå˜é‡è¯»å–
            self.base_url = os.getenv('CMS_API_BASE_URL', 'http://172.16.253.39/api/model/services')
            self.auth_token = os.getenv('CMS_AUTH_TOKEN')
            self.timeout = int(os.getenv('CMS_API_TIMEOUT', '30'))
        
        self.headers = {
            'Authorization': f'Bearer {self.auth_token}',
            'Content-Type': 'application/json'
        }
```

### æ·»åŠ æ–°çš„APIç«¯ç‚¹

```python
# åœ¨api/real_cms_client.pyä¸­æ·»åŠ 
class RealCMSClient:
    def get_equipment_list(self, region=None):
        """è·å–è®¾å¤‡åˆ—è¡¨"""
        endpoint = "/equipment/list"
        params = {'region': region} if region else {}
        return self._make_request('GET', endpoint, params=params)
    
    def get_alarm_history(self, equipment_id, start_time, end_time):
        """è·å–æŠ¥è­¦å†å²"""
        endpoint = f"/equipment/{equipment_id}/alarms"
        params = {
            'start_time': start_time,
            'end_time': end_time
        }
        return self._make_request('GET', endpoint, params=params)
```

## æ•°æ®åº“é…ç½®

### ğŸ—„ï¸ å‘é‡æ•°æ®åº“é…ç½®ï¼ˆå­˜å‚¨æ–‡æ¡£å‘é‡ï¼‰

**æˆ‘æƒ³æ›´æ¢å‘é‡æ•°æ®åº“ç±»å‹ï¼š**

**é€‰é¡¹1ï¼šChromaï¼ˆæ¨èæ–°æ‰‹ï¼Œè½»é‡çº§ï¼‰**
```yaml
vector_db:
  type: "chroma"
  config:
    persist_directory: "./data/chroma_db"  # æ•°æ®å­˜å‚¨ä½ç½®
    collection_name: "cms_vibration_docs"  # é›†åˆåç§°
    embedding_dimension: 1536  # å‘é‡ç»´åº¦ï¼ˆä¸embeddingæ¨¡å‹åŒ¹é…ï¼‰
```

**é€‰é¡¹2ï¼šFAISSï¼ˆé«˜æ€§èƒ½ï¼Œé€‚åˆå¤§æ•°æ®é‡ï¼‰**
```yaml
vector_db:
  type: "faiss"
  config:
    index_path: "./data/faiss_index"  # ç´¢å¼•æ–‡ä»¶è·¯å¾„
    dimension: 1536
    index_type: "IVF"  # ç´¢å¼•ç±»å‹
```

**é€‰é¡¹3ï¼šMilvusï¼ˆä¼ä¸šçº§ï¼Œåˆ†å¸ƒå¼ï¼‰**
```yaml
vector_db:
  type: "milvus"
  config:
    host: "localhost"
    port: 19530
    collection_name: "cms_vibration_docs"
    dimension: 1536
```

**âš ï¸ æ›´æ¢å‘é‡æ•°æ®åº“é…å¥—ä¿®æ”¹ï¼š**
1. å®‰è£…å¯¹åº”ä¾èµ–ï¼š
   ```bash
   # Chroma
   pip install chromadb
   
   # FAISS
   pip install faiss-cpu  # æˆ– faiss-gpu
   
   # Milvus
   pip install pymilvus
   ```
2. é‡æ–°æ„å»ºå‘é‡ç´¢å¼•ï¼š
   ```bash
   python scripts/rebuild_vector_index.py
   ```
3. æµ‹è¯•å‘é‡æ£€ç´¢åŠŸèƒ½

### ğŸª å…³ç³»æ•°æ®åº“é…ç½®ï¼ˆå­˜å‚¨ç»“æ„åŒ–æ•°æ®ï¼‰

**æˆ‘æƒ³æ›´æ¢å…³ç³»æ•°æ®åº“ï¼š**

**é€‰é¡¹1ï¼šSQLiteï¼ˆæ¨èæ–°æ‰‹ï¼Œæ— éœ€å®‰è£…ï¼‰**
```yaml
database:
  type: "sqlite"
  config:
    database_path: "./data/cms_vibration.db"  # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    timeout: 30
```

**é€‰é¡¹2ï¼šPostgreSQLï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰**
```yaml
database:
  type: "postgresql"
  config:
    host: "localhost"  # æ•°æ®åº“æœåŠ¡å™¨åœ°å€
    port: 5432
    username: "cms_user"  # å¿…é¡»ä¿®æ”¹
    password: "cms_password"  # å¿…é¡»ä¿®æ”¹
    database: "cms_vibration"  # æ•°æ®åº“å
    pool_size: 10
```

**é€‰é¡¹3ï¼šMySQL**
```yaml
database:
  type: "mysql"
  config:
    host: "localhost"
    port: 3306
    username: "cms_user"  # å¿…é¡»ä¿®æ”¹
    password: "cms_password"  # å¿…é¡»ä¿®æ”¹
    database: "cms_vibration"
    charset: "utf8mb4"
```

**âš ï¸ æ›´æ¢å…³ç³»æ•°æ®åº“é…å¥—ä¿®æ”¹ï¼š**

1. **å®‰è£…æ•°æ®åº“é©±åŠ¨ï¼š**
   ```bash
   # PostgreSQL
   pip install psycopg2-binary
   
   # MySQL
   pip install pymysql
   ```

2. **åˆ›å»ºæ•°æ®åº“å’Œç”¨æˆ·ï¼š**
   ```sql
   -- PostgreSQL
   CREATE DATABASE cms_vibration;
   CREATE USER cms_user WITH PASSWORD 'cms_password';
   GRANT ALL PRIVILEGES ON DATABASE cms_vibration TO cms_user;
   
   -- MySQL
   CREATE DATABASE cms_vibration CHARACTER SET utf8mb4;
   CREATE USER 'cms_user'@'localhost' IDENTIFIED BY 'cms_password';
   GRANT ALL PRIVILEGES ON cms_vibration.* TO 'cms_user'@'localhost';
   ```

3. **è¿è¡Œæ•°æ®åº“è¿ç§»ï¼š**
   ```bash
   python scripts/init_database.py
   ```

4. **æµ‹è¯•æ•°æ®åº“è¿æ¥ï¼š**
   ```bash
   python scripts/test_db_connection.py
   ```

### ğŸ”„ æ•°æ®åº“è¿ç§»æ­¥éª¤

**ä»SQLiteè¿ç§»åˆ°PostgreSQLï¼š**

1. **å¤‡ä»½ç°æœ‰æ•°æ®ï¼š**
   ```bash
   python scripts/backup_database.py --source sqlite --output backup.sql
   ```

2. **ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š**
   ```yaml
   # å°†database.typeä»"sqlite"æ”¹ä¸º"postgresql"
   database:
     type: "postgresql"
     config:
       host: "localhost"
       # ... å…¶ä»–é…ç½®
   ```

3. **æ¢å¤æ•°æ®ï¼š**
   ```bash
   python scripts/restore_database.py --target postgresql --input backup.sql
   ```

4. **éªŒè¯è¿ç§»ï¼š**
   ```bash
   python scripts/verify_migration.py
   ```

### ğŸ“Š æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

**å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¾ˆæ…¢ï¼š**

1. **è°ƒæ•´è¿æ¥æ± å¤§å°ï¼š**
   ```yaml
   database:
     config:
       pool_size: 20  # å¢åŠ è¿æ¥æ± 
       max_overflow: 30
   ```

2. **æ·»åŠ æ•°æ®åº“ç´¢å¼•ï¼š**
   ```bash
   python scripts/create_indexes.py
   ```

3. **å¯ç”¨æŸ¥è¯¢ç¼“å­˜ï¼š**
   ```yaml
   database:
     config:
       enable_cache: true
       cache_ttl: 3600  # ç¼“å­˜1å°æ—¶
   ```

## æ•°æ®åº“è¿ç§»

### SQLiteåˆ°PostgreSQL

1. **å®‰è£…PostgreSQLä¾èµ–ï¼š**
```bash
pip install psycopg2-binary
```

2. **ä¿®æ”¹æ•°æ®åº“é…ç½®ï¼š**
```yaml
# config.yaml
database:
  type: "postgresql"
  postgresql:
    host: "localhost"
    port: 5432
    database: "cms_vibration"
    username: "cms_user"
    password: "your_password"
    pool_size: 10
    max_overflow: 20
```

3. **æ•°æ®è¿ç§»è„šæœ¬ï¼š**
```python
# migrate_database.py
import sqlite3
import psycopg2
from sqlalchemy import create_engine

def migrate_sqlite_to_postgresql():
    # SQLiteè¿æ¥
    sqlite_conn = sqlite3.connect('data/cms_data.db')
    
    # PostgreSQLè¿æ¥
    pg_engine = create_engine(
        'postgresql://cms_user:password@localhost:5432/cms_vibration'
    )
    
    # è¿ç§»æ•°æ®
    tables = ['reports', 'analysis_results', 'user_sessions']
    
    for table in tables:
        df = pd.read_sql_query(f"SELECT * FROM {table}", sqlite_conn)
        df.to_sql(table, pg_engine, if_exists='replace', index=False)
    
    sqlite_conn.close()
    print("æ•°æ®åº“è¿ç§»å®Œæˆ")

if __name__ == "__main__":
    migrate_sqlite_to_postgresql()
```

### å‘é‡æ•°æ®åº“è¿ç§»

#### ä»ChromaDBè¿ç§»åˆ°Pinecone

```python
# migrate_vector_db.py
import chromadb
import pinecone
from tqdm import tqdm

def migrate_chromadb_to_pinecone():
    # åˆå§‹åŒ–ChromaDB
    chroma_client = chromadb.PersistentClient(path="./data/vector_db")
    collection = chroma_client.get_collection("cms_knowledge")
    
    # åˆå§‹åŒ–Pinecone
    pinecone.init(
        api_key="your-pinecone-key",
        environment="us-west1-gcp"
    )
    
    # åˆ›å»ºç´¢å¼•
    if "cms-vibration" not in pinecone.list_indexes():
        pinecone.create_index(
            "cms-vibration",
            dimension=384,  # æ ¹æ®åµŒå…¥æ¨¡å‹ç»´åº¦è°ƒæ•´
            metric="cosine"
        )
    
    index = pinecone.Index("cms-vibration")
    
    # è·å–æ‰€æœ‰æ•°æ®
    results = collection.get(include=['embeddings', 'metadatas', 'documents'])
    
    # æ‰¹é‡ä¸Šä¼ åˆ°Pinecone
    batch_size = 100
    for i in tqdm(range(0, len(results['ids']), batch_size)):
        batch_ids = results['ids'][i:i+batch_size]
        batch_embeddings = results['embeddings'][i:i+batch_size]
        batch_metadata = results['metadatas'][i:i+batch_size]
        
        vectors = [
            {
                'id': batch_ids[j],
                'values': batch_embeddings[j],
                'metadata': batch_metadata[j]
            }
            for j in range(len(batch_ids))
        ]
        
        index.upsert(vectors=vectors)
    
    print("å‘é‡æ•°æ®åº“è¿ç§»å®Œæˆ")

if __name__ == "__main__":
    migrate_chromadb_to_pinecone()
```

## çŸ¥è¯†åº“è¿ç§»

### çŸ¥è¯†åº“ç»“æ„

```
knowledge_base/
â”œâ”€â”€ documents/          # åŸå§‹æ–‡æ¡£
â”‚   â”œâ”€â”€ manuals/       # è®¾å¤‡æ‰‹å†Œ
â”‚   â”œâ”€â”€ standards/     # è¡Œä¸šæ ‡å‡†
â”‚   â””â”€â”€ cases/         # æ¡ˆä¾‹æ–‡æ¡£
â”œâ”€â”€ embeddings/        # å‘é‡åµŒå…¥
â”œâ”€â”€ metadata/          # å…ƒæ•°æ®
â””â”€â”€ templates/         # æŠ¥å‘Šæ¨¡æ¿
```

### çŸ¥è¯†åº“è¿ç§»è„šæœ¬

```python
# migrate_knowledge.py
import os
import shutil
from pathlib import Path

def migrate_knowledge_base(old_path, new_path):
    """è¿ç§»çŸ¥è¯†åº“"""
    old_kb = Path(old_path)
    new_kb = Path(new_path)
    
    # åˆ›å»ºæ–°ç›®å½•ç»“æ„
    new_kb.mkdir(parents=True, exist_ok=True)
    (new_kb / "documents").mkdir(exist_ok=True)
    (new_kb / "embeddings").mkdir(exist_ok=True)
    (new_kb / "metadata").mkdir(exist_ok=True)
    (new_kb / "templates").mkdir(exist_ok=True)
    
    # å¤åˆ¶æ–‡æ¡£
    if (old_kb / "documents").exists():
        shutil.copytree(
            old_kb / "documents",
            new_kb / "documents",
            dirs_exist_ok=True
        )
    
    # é‡æ–°ç”ŸæˆåµŒå…¥ï¼ˆå› ä¸ºå¯èƒ½ä½¿ç”¨ä¸åŒçš„åµŒå…¥æ¨¡å‹ï¼‰
    from knowledge.knowledge_manager import KnowledgeManager
    
    km = KnowledgeManager(str(new_kb))
    km.rebuild_embeddings()
    
    print(f"çŸ¥è¯†åº“è¿ç§»å®Œæˆ: {old_path} -> {new_path}")

def update_knowledge_config(config_path, new_kb_path):
    """æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„çŸ¥è¯†åº“è·¯å¾„"""
    import yaml
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    config['knowledge'] = {
        'base_path': new_kb_path,
        'auto_update': True,
        'chunk_size': 1000,
        'chunk_overlap': 200
    }
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"é…ç½®æ–‡ä»¶å·²æ›´æ–°: {config_path}")

if __name__ == "__main__":
    migrate_knowledge_base(
        "./old_knowledge_base",
        "./knowledge_base"
    )
    update_knowledge_config("config.yaml", "./knowledge_base")
```

## æ¨¡æ¿è‡ªå®šä¹‰

### æŠ¥å‘Šæ¨¡æ¿é…ç½®

åœ¨ `report_templates/` ç›®å½•ä¸‹åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿ï¼š

```python
# report_templates/custom/my_template.py
from knowledge.template_manager import BaseTemplate

class MyCustomTemplate(BaseTemplate):
    def __init__(self):
        super().__init__()
        self.template_name = "my_custom_template"
        self.description = "æˆ‘çš„è‡ªå®šä¹‰æŠ¥å‘Šæ¨¡æ¿"
    
    def generate_structure(self, data):
        return {
            "title": "è‡ªå®šä¹‰æŒ¯åŠ¨åˆ†ææŠ¥å‘Š",
            "sections": [
                {
                    "name": "æ¦‚è¿°",
                    "content": self._generate_overview(data)
                },
                {
                    "name": "è¯¦ç»†åˆ†æ",
                    "content": self._generate_analysis(data)
                },
                {
                    "name": "å»ºè®®æªæ–½",
                    "content": self._generate_recommendations(data)
                }
            ]
        }
    
    def _generate_overview(self, data):
        # è‡ªå®šä¹‰æ¦‚è¿°ç”Ÿæˆé€»è¾‘
        pass
    
    def _generate_analysis(self, data):
        # è‡ªå®šä¹‰åˆ†æç”Ÿæˆé€»è¾‘
        pass
    
    def _generate_recommendations(self, data):
        # è‡ªå®šä¹‰å»ºè®®ç”Ÿæˆé€»è¾‘
        pass
```

### æ³¨å†Œè‡ªå®šä¹‰æ¨¡æ¿

```python
# åœ¨knowledge/template_manager.pyä¸­æ³¨å†Œ
from report_templates.custom.my_template import MyCustomTemplate

class TemplateManager:
    def __init__(self):
        self.templates = {
            "default": DefaultTemplate(),
            "comprehensive": ComprehensiveTemplate(),
            "maintenance": MaintenanceTemplate(),
            "my_custom": MyCustomTemplate(),  # æ·»åŠ è‡ªå®šä¹‰æ¨¡æ¿
        }
```

## æ€§èƒ½å‚æ•°è°ƒä¼˜

### å†…å­˜ä¼˜åŒ–é…ç½®

```yaml
# config.yaml
performance:
  # å†…å­˜ç®¡ç†
  memory:
    max_usage: "8GB"
    gc_threshold: 0.8
    clear_cache_interval: 3600
  
  # æ¨¡å‹ä¼˜åŒ–
  model:
    use_quantization: true
    quantization_bits: 4
    use_flash_attention: true
    gradient_checkpointing: true
  
  # å¹¶å‘å¤„ç†
  concurrency:
    max_workers: 4
    batch_size: 32
    queue_size: 100
  
  # ç¼“å­˜ç­–ç•¥
  cache:
    enabled: true
    ttl: 3600
    max_size: "2GB"
    compression: true
```

### GPUé…ç½®ä¼˜åŒ–

```python
# utils/gpu_optimizer.py
import torch
import os

def optimize_gpu_settings():
    """ä¼˜åŒ–GPUè®¾ç½®"""
    if torch.cuda.is_available():
        # è®¾ç½®å†…å­˜åˆ†é…ç­–ç•¥
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
        
        # å¯ç”¨cudnnä¼˜åŒ–
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        # è®¾ç½®å†…å­˜å¢é•¿ç­–ç•¥
        torch.cuda.empty_cache()
        
        print(f"GPUä¼˜åŒ–å®Œæˆï¼Œå¯ç”¨æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    else:
        print("æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUæ¨¡å¼")

def set_mixed_precision(enabled=True):
    """è®¾ç½®æ··åˆç²¾åº¦è®­ç»ƒ"""
    if enabled and torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        print("æ··åˆç²¾åº¦å·²å¯ç”¨")
```

## ç¯å¢ƒå˜é‡é…ç½®

### åˆ›å»ºç¯å¢ƒé…ç½®æ–‡ä»¶

é¡¹ç›®ç°åœ¨æ”¯æŒ`.env`æ–‡ä»¶é…ç½®ï¼Œå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–`config.yaml`ä¸­çš„è®¾ç½®ã€‚é¦–å…ˆå¤åˆ¶ç¤ºä¾‹æ–‡ä»¶ï¼š

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ç¯å¢ƒå˜é‡æ–‡ä»¶
vim .env
```

`.env`æ–‡ä»¶å†…å®¹ç¤ºä¾‹ï¼š

```bash
# LLMé…ç½®
CMS_MODEL_TYPE=deepseek_api
CMS_OPENAI_API_KEY=sk-your-openai-key
CMS_OPENAI_BASE_URL=https://api.openai.com/v1
CMS_DEEPSEEK_API_KEY=sk-your-deepseek-key
CMS_LOCAL_MODEL_PATH=/path/to/local/model
CMS_CUSTOM_API_KEY=your-custom-api-key
CMS_CUSTOM_BASE_URL=https://your-custom-api.com/v1

# åµŒå…¥æ¨¡å‹é…ç½®
CMS_EMBEDDING_TYPE=huggingface
CMS_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CMS_EMBEDDING_CACHE_DIR=./cache/embeddings

# æ•°æ®åº“é…ç½®
CMS_DB_TYPE=sqlite
CMS_DB_PATH=./data/cms_vibration.db
CMS_DB_HOST=localhost
CMS_DB_PASSWORD=your_db_password

# å¤–éƒ¨APIé…ç½®
CMS_EXTERNAL_API_ENABLED=true
CMS_CMS_API_KEY=your_cms_api_key
CMS_CMS_API_URL=http://172.16.253.39/api/model/services

# Streamlité…ç½®
CMS_STREAMLIT_ENABLED=true
CMS_STREAMLIT_PORT=8501
CMS_STREAMLIT_HOST=0.0.0.0

# ç³»ç»Ÿé…ç½®
CMS_LOG_LEVEL=INFO
CMS_DEBUG=false
```

### ç¯å¢ƒå˜é‡åŠ è½½

é¡¹ç›®å·²é›†æˆç¯å¢ƒå˜é‡åŠ è½½åŠŸèƒ½ï¼Œé…ç½®åŠ è½½å™¨ä¼šè‡ªåŠ¨ï¼š

1. åŠ è½½`.env`æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
2. ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–`config.yaml`ä¸­çš„å¯¹åº”é…ç½®
3. æ”¯æŒç±»å‹è½¬æ¢ï¼ˆå­—ç¬¦ä¸²ã€å¸ƒå°”å€¼ã€æ•°å­—ï¼‰

```python
# ä½¿ç”¨é…ç½®åŠ è½½å™¨ï¼ˆè‡ªåŠ¨åŠ è½½.envæ–‡ä»¶ï¼‰
from config.config_loader import get_config

# è·å–é…ç½®
config = get_config()
model_config = config.get_model_config()
database_config = config.get_database_config()

# æ£€æŸ¥é…ç½®
print(f"å½“å‰æ¨¡å‹ç±»å‹: {model_config['type']}")
print(f"æ•°æ®åº“ç±»å‹: {database_config['type']}")
print(f"è°ƒè¯•æ¨¡å¼: {config.is_debug_mode()}")
```

### ç¯å¢ƒå˜é‡æ˜ å°„

ç³»ç»Ÿæ”¯æŒä»¥ä¸‹ç¯å¢ƒå˜é‡æ˜ å°„åˆ°é…ç½®æ–‡ä»¶ï¼š

| ç¯å¢ƒå˜é‡ | é…ç½®è·¯å¾„ | è¯´æ˜ |
|---------|---------|------|
| `CMS_MODEL_TYPE` | `model.type` | æ¨¡å‹ç±»å‹ |
| `CMS_OPENAI_API_KEY` | `model.openai.api_key` | OpenAI APIå¯†é’¥ |
| `CMS_DEEPSEEK_API_KEY` | `model.deepseek_api.api_key` | DeepSeek APIå¯†é’¥ |
| `CMS_DB_TYPE` | `database.type` | æ•°æ®åº“ç±»å‹ |
| `CMS_DB_PATH` | `database.sqlite.path` | SQLiteæ•°æ®åº“è·¯å¾„ |
| `CMS_LOG_LEVEL` | `system.logging.level` | æ—¥å¿—çº§åˆ« |
| `CMS_DEBUG` | `development.debug` | è°ƒè¯•æ¨¡å¼ |

## å¸¸è§è¿ç§»åœºæ™¯

### ğŸš€ æµ‹è¯•ç¯å¢ƒåˆ°ç”Ÿäº§ç¯å¢ƒ

**æˆ‘è¦å°†ç³»ç»Ÿéƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼š**

1. **é…ç½®æ–‡ä»¶è°ƒæ•´**
   ```yaml
   # ç”Ÿäº§ç¯å¢ƒé…ç½®è¦ç‚¹
   logging:
     level: "INFO"  # ä»DEBUGæ”¹ä¸ºINFO
   
   database:
     type: "postgresql"  # ä»sqliteæ”¹ä¸ºpostgresql
     config:
       host: "prod-db-server"
       # ... ç”Ÿäº§æ•°æ®åº“é…ç½®
   
   model:
     openai:
       api_key: "${OPENAI_API_KEY}"  # ä½¿ç”¨ç¯å¢ƒå˜é‡
   ```

2. **æ€§èƒ½ä¼˜åŒ–**
   ```yaml
   performance:
     max_workers: 8  # å¢åŠ å·¥ä½œè¿›ç¨‹
     max_concurrent_requests: 200
   
   cache:
     type: "redis"  # å¯ç”¨Redisç¼“å­˜
     config:
       host: "redis-cluster"
   ```

3. **å®‰å…¨åŠ å›º**
   ```bash
   # é…ç½®HTTPS
   sudo certbot --nginx -d yourdomain.com
   
   # é…ç½®é˜²ç«å¢™
   sudo ufw enable
   sudo ufw allow 443/tcp
   sudo ufw allow 80/tcp
   ```

### ğŸ® GPUæœåŠ¡å™¨åˆ‡æ¢

**æˆ‘è¦åœ¨GPUæœåŠ¡å™¨ä¸Šè¿è¡Œï¼š**

1. **æ£€æŸ¥GPUç¯å¢ƒ**
   ```bash
   # æ£€æŸ¥GPUçŠ¶æ€
   nvidia-smi
   
   # æ£€æŸ¥CUDAç‰ˆæœ¬
   nvcc --version
   
   # æµ‹è¯•PyTorch GPUæ”¯æŒ
   python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}, Device count: {torch.cuda.device_count()}')"
   ```

2. **å®‰è£…GPUç‰ˆæœ¬ä¾èµ–**
   ```bash
   # å®‰è£…GPUç‰ˆPyTorchï¼ˆæ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©ï¼‰
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   
   # å®‰è£…GPUç‰ˆFAISS
   pip install faiss-gpu
   
   # å®‰è£…å…¶ä»–GPUåŠ é€Ÿåº“
   pip install cupy-cuda11x  # å¯é€‰
   ```

3. **ä¿®æ”¹é…ç½®å¯ç”¨GPU**
   ```yaml
   model:
     device: "cuda"  # å¯ç”¨GPU
     gpu_memory_fraction: 0.8  # ä½¿ç”¨80%æ˜¾å­˜
     
   embedding:
     device: "cuda"
     batch_size: 32  # GPUå¯ä»¥å¤„ç†æ›´å¤§æ‰¹æ¬¡
   
   vector_db:
     config:
       use_gpu: true  # å¦‚æœæ”¯æŒGPUåŠ é€Ÿ
   ```

4. **GPUæ€§èƒ½ç›‘æ§**
   ```bash
   # å®æ—¶ç›‘æ§GPUä½¿ç”¨
   watch -n 1 nvidia-smi
   
   # æŸ¥çœ‹GPUå†…å­˜ä½¿ç”¨
   python -c "import torch; print(f'GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB / {torch.cuda.memory_reserved()/1024**3:.2f}GB')"
   ```

### ğŸ¢ å¤šç§Ÿæˆ·éƒ¨ç½²

**æˆ‘è¦ä¸ºå¤šä¸ªå®¢æˆ·éƒ¨ç½²ç‹¬ç«‹å®ä¾‹ï¼š**

1. **é…ç½®éš”ç¦»ç­–ç•¥**
   ```bash
   # ä¸ºæ¯ä¸ªç§Ÿæˆ·åˆ›å»ºç‹¬ç«‹ç›®å½•
   mkdir -p /opt/cms_rag/tenant_a
   mkdir -p /opt/cms_rag/tenant_b
   
   # å¤åˆ¶é…ç½®æ¨¡æ¿
   cp config/config.yaml /opt/cms_rag/tenant_a/config.yaml
   cp config/config.yaml /opt/cms_rag/tenant_b/config.yaml
   ```

2. **æ•°æ®åº“éš”ç¦»**
   ```yaml
   # tenant_a/config.yaml
   database:
     config:
       database: "cms_vibration_tenant_a"
   
   vector_db:
     config:
       collection_name: "docs_tenant_a"
   
   # tenant_b/config.yaml
   database:
     config:
       database: "cms_vibration_tenant_b"
   
   vector_db:
     config:
       collection_name: "docs_tenant_b"
   ```

3. **ç«¯å£å’ŒæœåŠ¡éš”ç¦»**
   ```bash
   # ç§Ÿæˆ·A - ç«¯å£8000
   cd /opt/cms_rag/tenant_a
   python start_api_server.py --port 8000 --config config.yaml
   
   # ç§Ÿæˆ·B - ç«¯å£8001
   cd /opt/cms_rag/tenant_b
   python start_api_server.py --port 8001 --config config.yaml
   ```

4. **èµ„æºé™åˆ¶é…ç½®**
   ```yaml
   # æ¯ä¸ªç§Ÿæˆ·çš„èµ„æºé™åˆ¶
   performance:
     max_workers: 2  # é™åˆ¶å·¥ä½œè¿›ç¨‹æ•°
     max_concurrent_requests: 50  # é™åˆ¶å¹¶å‘è¯·æ±‚
     max_memory_usage: "1GB"  # é™åˆ¶å†…å­˜ä½¿ç”¨
   
   security:
     rate_limit:
       requests_per_minute: 30  # é™åˆ¶è¯·æ±‚é¢‘ç‡
   ```

## ğŸ†˜ å¸¸è§é—®é¢˜è§£ç­”ï¼ˆFAQï¼‰

### Q1: å¯åŠ¨æ—¶æç¤º"æ¨¡å—æœªæ‰¾åˆ°"é”™è¯¯

**A:** æ£€æŸ¥ä¾èµ–å®‰è£…å’ŒPythonè·¯å¾„
```bash
# é‡æ–°å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æ£€æŸ¥Pythonè·¯å¾„
echo $PYTHONPATH
export PYTHONPATH=/root/autodl-tmp/cms_vibration_rag:$PYTHONPATH

# æˆ–ä½¿ç”¨ç›¸å¯¹å¯¼å…¥
cd /root/autodl-tmp/cms_vibration_rag
python -m streamlit run streamlit_app.py
```

### Q2: APIè°ƒç”¨è¶…æ—¶æˆ–è¿æ¥å¤±è´¥

**A:** æ£€æŸ¥ç½‘ç»œå’ŒAPIé…ç½®
```bash
# æµ‹è¯•ç½‘ç»œè¿é€šæ€§
curl -I https://api.openai.com

# æ£€æŸ¥APIå¯†é’¥
echo $OPENAI_API_KEY

# æµ‹è¯•APIè°ƒç”¨
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     "https://api.openai.com/v1/models"
```

### Q3: å‘é‡æ•°æ®åº“æ£€ç´¢ç»“æœä¸å‡†ç¡®

**A:** é‡å»ºå‘é‡ç´¢å¼•å’Œè°ƒæ•´å‚æ•°
```bash
# æ¸…ç†æ—§ç´¢å¼•
rm -rf data/chroma_db/*

# é‡æ–°æ„å»ºç´¢å¼•
python scripts/rebuild_vector_index.py

# è°ƒæ•´æ£€ç´¢å‚æ•°
# åœ¨config.yamlä¸­ä¿®æ”¹ï¼š
vector_db:
  config:
    similarity_threshold: 0.7  # é™ä½é˜ˆå€¼
    max_results: 10  # å¢åŠ ç»“æœæ•°é‡
```

### Q4: å†…å­˜ä½¿ç”¨è¿‡é«˜å¯¼è‡´ç³»ç»Ÿå¡é¡¿

**A:** ä¼˜åŒ–å†…å­˜é…ç½®
```yaml
# åœ¨config.yamlä¸­è°ƒæ•´
performance:
  max_memory_usage: "1GB"  # é™åˆ¶å†…å­˜ä½¿ç”¨
  gc_threshold: 0.6  # é™ä½åƒåœ¾å›æ”¶é˜ˆå€¼

model:
  max_tokens: 2048  # å‡å°‘tokenæ•°é‡
  batch_size: 1  # å‡å°‘æ‰¹å¤„ç†å¤§å°
```

### Q5: æ•°æ®åº“è¿æ¥å¤±è´¥

**A:** æ£€æŸ¥æ•°æ®åº“é…ç½®å’Œè¿æ¥
```bash
# æµ‹è¯•SQLite
ls -la data/cms_vibration.db

# æµ‹è¯•PostgreSQL
psql -h localhost -U cms_user -d cms_vibration -c "SELECT 1;"

# æ£€æŸ¥æ•°æ®åº“æœåŠ¡çŠ¶æ€
sudo systemctl status postgresql
```

### Q6: æ–‡ä»¶ä¸Šä¼ å¤±è´¥

**A:** æ£€æŸ¥æ–‡ä»¶æƒé™å’Œå¤§å°é™åˆ¶
```bash
# æ£€æŸ¥ä¸Šä¼ ç›®å½•æƒé™
ls -la data/uploads/
chmod 755 data/uploads/

# æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
# åœ¨config.yamlä¸­è°ƒæ•´ï¼š
security:
  upload:
    max_file_size: "50MB"  # å¢åŠ æ–‡ä»¶å¤§å°é™åˆ¶
```

## ğŸ”§ æ•…éšœæ’é™¤æ­¥éª¤

### 1. ç³»ç»Ÿæ— æ³•å¯åŠ¨

**æ’æŸ¥æ­¥éª¤ï¼š**
```bash
# 1. æ£€æŸ¥Pythonç¯å¢ƒ
python --version
which python

# 2. æ£€æŸ¥ä¾èµ–
pip list | grep -E "streamlit|fastapi|openai"

# 3. æ£€æŸ¥é…ç½®æ–‡ä»¶
python -c "import yaml; yaml.safe_load(open('config/config.yaml'))"

# 4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯
python streamlit_app.py --debug
```

### 2. APIå“åº”ç¼“æ…¢

**æ’æŸ¥æ­¥éª¤ï¼š**
```bash
# 1. æ£€æŸ¥ç³»ç»Ÿèµ„æº
htop
df -h

# 2. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
ping api.openai.com

# 3. æŸ¥çœ‹æ—¥å¿—
tail -f logs/cms_vibration.log

# 4. æµ‹è¯•APIæ€§èƒ½
time curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "test"}'
```

### 3. æ•°æ®æ£€ç´¢ä¸å‡†ç¡®

**æ’æŸ¥æ­¥éª¤ï¼š**
```bash
# 1. æ£€æŸ¥å‘é‡æ•°æ®åº“
ls -la data/chroma_db/

# 2. æµ‹è¯•embedding
python -c "from sentence_transformers import SentenceTransformer; model = SentenceTransformer('all-MiniLM-L6-v2'); print(model.encode(['test']))"

# 3. é‡å»ºç´¢å¼•
python scripts/rebuild_vector_index.py --verbose

# 4. è°ƒæ•´æ£€ç´¢å‚æ•°
# ä¿®æ”¹config.yamlä¸­çš„similarity_threshold
```

## æ•…éšœæ’é™¤

### é…ç½®éªŒè¯è„šæœ¬

```python
# validate_config.py
import yaml
import os
from pathlib import Path

def validate_config(config_path="config.yaml"):
    """éªŒè¯é…ç½®æ–‡ä»¶"""
    errors = []
    warnings = []
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(config_path).exists():
        errors.append(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return errors, warnings
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except yaml.YAMLError as e:
        errors.append(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return errors, warnings
    
    # éªŒè¯å¿…éœ€çš„é…ç½®é¡¹
    required_sections = ['api', 'llm', 'embedding', 'vector_db']
    for section in required_sections:
        if section not in config:
            errors.append(f"ç¼ºå°‘å¿…éœ€çš„é…ç½®èŠ‚: {section}")
    
    # éªŒè¯APIé…ç½®
    if 'api' in config:
        api_config = config['api']
        if not api_config.get('cms_base_url'):
            errors.append("ç¼ºå°‘APIåŸºç¡€URLé…ç½®")
        if not api_config.get('auth_token'):
            warnings.append("æœªé…ç½®APIè®¤è¯ä»¤ç‰Œ")
    
    # éªŒè¯LLMé…ç½®
    if 'llm' in config:
        llm_config = config['llm']
        provider = llm_config.get('provider')
        if not provider:
            errors.append("æœªæŒ‡å®šLLMæä¾›å•†")
        elif provider not in ['openai', 'deepseek', 'qwen', 'local']:
            errors.append(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
        
        # éªŒè¯æä¾›å•†ç‰¹å®šé…ç½®
        if provider in llm_config:
            provider_config = llm_config[provider]
            if provider != 'local' and not provider_config.get('api_key'):
                errors.append(f"ç¼ºå°‘{provider}çš„APIå¯†é’¥")
    
    # éªŒè¯è·¯å¾„
    paths_to_check = [
        ('knowledge_base', config.get('knowledge', {}).get('base_path')),
        ('cache_dir', config.get('processing', {}).get('cache_dir')),
        ('output_dir', config.get('output', {}).get('reports', {}).get('output_dir'))
    ]
    
    for name, path in paths_to_check:
        if path and not Path(path).exists():
            warnings.append(f"{name}è·¯å¾„ä¸å­˜åœ¨: {path}")
    
    return errors, warnings

def fix_common_issues(config_path="config.yaml"):
    """ä¿®å¤å¸¸è§é…ç½®é—®é¢˜"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºç¼ºå¤±çš„ç›®å½•
    dirs_to_create = [
        config.get('processing', {}).get('cache_dir', './cache'),
        config.get('output', {}).get('reports', {}).get('output_dir', './output'),
        './data/vector_db',
        './knowledge_base'
    ]
    
    for dir_path in dirs_to_create:
        if dir_path:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            print(f"åˆ›å»ºç›®å½•: {dir_path}")
    
    print("å¸¸è§é—®é¢˜ä¿®å¤å®Œæˆ")

if __name__ == "__main__":
    errors, warnings = validate_config()
    
    if errors:
        print("é…ç½®é”™è¯¯:")
        for error in errors:
            print(f"  âŒ {error}")
    
    if warnings:
        print("é…ç½®è­¦å‘Š:")
        for warning in warnings:
            print(f"  âš ï¸ {warning}")
    
    if not errors and not warnings:
        print("âœ… é…ç½®éªŒè¯é€šè¿‡")
    
    if errors or warnings:
        fix_common_issues()
```

### å¸¸è§é—®é¢˜è§£å†³

#### 1. æ¨¡å‹åŠ è½½å¤±è´¥

**é—®é¢˜ï¼š** `OSError: Can't load tokenizer`

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ¸…ç†æ¨¡å‹ç¼“å­˜
rm -rf ~/.cache/huggingface/

# é‡æ–°ä¸‹è½½æ¨¡å‹
python -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('your-model-name')"
```

#### 2. APIè¿æ¥è¶…æ—¶

**é—®é¢˜ï¼š** `requests.exceptions.Timeout`

**è§£å†³æ–¹æ¡ˆï¼š**
```yaml
# å¢åŠ è¶…æ—¶æ—¶é—´
api:
  timeout: 60
  retry_times: 5
  retry_delay: 2
```

#### 3. å†…å­˜ä¸è¶³

**é—®é¢˜ï¼š** `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆï¼š**
```yaml
# å¯ç”¨æ¨¡å‹é‡åŒ–
llm:
  local:
    load_in_4bit: true
    max_memory: "6GB"

# å‡å°‘æ‰¹å¤„ç†å¤§å°
processing:
  batch_size: 16
```

#### 4. å‘é‡æ•°æ®åº“è¿æ¥å¤±è´¥

**é—®é¢˜ï¼š** `chromadb.errors.InvalidDimensionException`

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# é‡å»ºå‘é‡æ•°æ®åº“
python -c "
from knowledge.knowledge_manager import KnowledgeManager
km = KnowledgeManager()
km.rebuild_embeddings()
"
```

### è¿ç§»æ£€æŸ¥æ¸…å•

- [ ] å¤‡ä»½åŸå§‹é…ç½®å’Œæ•°æ®
- [ ] éªŒè¯æ–°ç¯å¢ƒçš„ç³»ç»Ÿè¦æ±‚
- [ ] æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„APIç«¯ç‚¹
- [ ] é…ç½®æ–°çš„è®¤è¯ä¿¡æ¯
- [ ] è¿ç§»çŸ¥è¯†åº“å’Œå‘é‡æ•°æ®åº“
- [ ] æµ‹è¯•æ¨¡å‹åŠ è½½å’Œæ¨ç†
- [ ] éªŒè¯APIè¿æ¥å’Œæ•°æ®è·å–
- [ ] è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•
- [ ] æ£€æŸ¥æ—¥å¿—è¾“å‡º
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨
- [ ] æ–‡æ¡£æ›´æ–°

---

**ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2025-01-14  
**ç»´æŠ¤è€…**: CMSå¼€å‘å›¢é˜Ÿ

å¦‚éœ€æ›´å¤šå¸®åŠ©ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒå›¢é˜Ÿã€‚